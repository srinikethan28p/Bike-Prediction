{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88094478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, BatchNormalization, Dropout, LSTM\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import regularizers\n",
    "from sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report, accuracy_score, f1_score\n",
    "from keras import callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe9c1fce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrin\\OneDrive - The University of Texas at Dallas\\Desktop\\Srini UTD\\BUAN 6341\n"
     ]
    }
   ],
   "source": [
    "working_directory = os.getcwd()\n",
    "print(working_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55bf97b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'C:\\Users\\psrin\\OneDrive - The University of Texas at Dallas\\Desktop\\Srini UTD\\BUAN 6341\\Assignment\\SeoulBikeData.csv',encoding = 'unicode_escape',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a74b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'/Users/srini/OneDrive - The University of Texas at Dallas/Desktop/Srini UTD/BUAN 6341/Assignment/SeoulBikeData.csv',encoding = 'unicode_escape',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d543fb06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rented Bike Count</th>\n",
       "      <th>Hour</th>\n",
       "      <th>Temperature(째C)</th>\n",
       "      <th>Humidity(%)</th>\n",
       "      <th>Wind speed (m/s)</th>\n",
       "      <th>Visibility (10m)</th>\n",
       "      <th>Dew point temperature(째C)</th>\n",
       "      <th>Solar Radiation (MJ/m2)</th>\n",
       "      <th>Rainfall(mm)</th>\n",
       "      <th>Snowfall (cm)</th>\n",
       "      <th>Seasons</th>\n",
       "      <th>Holiday</th>\n",
       "      <th>Functioning Day</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>01/12/2017</th>\n",
       "      <td>254</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/12/2017</th>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/12/2017</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/12/2017</th>\n",
       "      <td>107</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>01/12/2017</th>\n",
       "      <td>78</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>No Holiday</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Rented Bike Count  Hour  Temperature(째C)  Humidity(%)  \\\n",
       "Date                                                                \n",
       "01/12/2017                254     0             -5.2           37   \n",
       "01/12/2017                204     1             -5.5           38   \n",
       "01/12/2017                173     2             -6.0           39   \n",
       "01/12/2017                107     3             -6.2           40   \n",
       "01/12/2017                 78     4             -6.0           36   \n",
       "\n",
       "            Wind speed (m/s)  Visibility (10m)  Dew point temperature(째C)  \\\n",
       "Date                                                                        \n",
       "01/12/2017               2.2              2000                      -17.6   \n",
       "01/12/2017               0.8              2000                      -17.6   \n",
       "01/12/2017               1.0              2000                      -17.7   \n",
       "01/12/2017               0.9              2000                      -17.6   \n",
       "01/12/2017               2.3              2000                      -18.6   \n",
       "\n",
       "            Solar Radiation (MJ/m2)  Rainfall(mm)  Snowfall (cm) Seasons  \\\n",
       "Date                                                                       \n",
       "01/12/2017                      0.0           0.0            0.0  Winter   \n",
       "01/12/2017                      0.0           0.0            0.0  Winter   \n",
       "01/12/2017                      0.0           0.0            0.0  Winter   \n",
       "01/12/2017                      0.0           0.0            0.0  Winter   \n",
       "01/12/2017                      0.0           0.0            0.0  Winter   \n",
       "\n",
       "               Holiday Functioning Day  \n",
       "Date                                    \n",
       "01/12/2017  No Holiday             Yes  \n",
       "01/12/2017  No Holiday             Yes  \n",
       "01/12/2017  No Holiday             Yes  \n",
       "01/12/2017  No Holiday             Yes  \n",
       "01/12/2017  No Holiday             Yes  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11ba965",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['rented_bike_count', 'hour','temperature_in_c','humidity_percentage','wind_speed_mps','visibility_10m','dew_point_temperature_in_c','solar_radiation','rainfall_mm','snowfall_cm','seasons','holiday','functioning_day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45750763",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[\"rented_bike_count\"] < 704.602, \"rented_bike_count\"] = 0\n",
    "data.loc[data[\"rented_bike_count\"] >= 704.602, \"rented_bike_count\"] = 1\n",
    "data.loc[data[\"seasons\"] == \"Spring\", \"seasons\"] = 1\n",
    "data.loc[data[\"seasons\"] == \"Summer\", \"seasons\"] = 2\n",
    "data.loc[data[\"seasons\"] == \"Autumn\", \"seasons\"] = 3\n",
    "data.loc[data[\"seasons\"] == \"Winter\", \"seasons\"] = 4\n",
    "data.loc[data[\"functioning_day\"] == \"Yes\", \"functioning_day\"] = 1\n",
    "data.loc[data[\"functioning_day\"] == \"No\", \"functioning_day\"] = 0\n",
    "data.loc[data[\"holiday\"] == \"Holiday\", \"holiday\"] = 1\n",
    "data.loc[data[\"holiday\"] == \"No Holiday\", \"holiday\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7579558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5238\n",
       "1    3522\n",
       "Name: rented_bike_count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rented_bike_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95eff2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>37</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-5.5</td>\n",
       "      <td>38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>40</td>\n",
       "      <td>0.9</td>\n",
       "      <td>2000</td>\n",
       "      <td>-17.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>36</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2000</td>\n",
       "      <td>-18.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0   1    2   3    4     5     6    7    8    9  10 11 12\n",
       "0   0   0 -5.2  37  2.2  2000 -17.6  0.0  0.0  0.0  4  0  1\n",
       "1   0   1 -5.5  38  0.8  2000 -17.6  0.0  0.0  0.0  4  0  1\n",
       "2   0   2 -6.0  39  1.0  2000 -17.7  0.0  0.0  0.0  4  0  1\n",
       "3   0   3 -6.2  40  0.9  2000 -17.6  0.0  0.0  0.0  4  0  1\n",
       "4   0   4 -6.0  36  2.3  2000 -18.6  0.0  0.0  0.0  4  0  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.reset_index(drop=True)\n",
    "data.columns = [0,1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcd2bb0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6132, 12) (2628, 12)\n",
      "(6132, 1) (2628, 1)\n"
     ]
    }
   ],
   "source": [
    "x = data[[1,2,3,4,5,6,7,8,9,10,11,12]].values\n",
    "y = data[[0]].values\n",
    "x_train, x_test = x[:6132,:], x[6132:,:]\n",
    "print(x_train.shape, x_test.shape)\n",
    "y_train, y_test = y[:6132,:], y[6132:,:]\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01a63fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1]), array([0, 0, 0, ..., 0, 1, 0]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u = np.unique(y, return_inverse = True)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e040b706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fcd1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f5f1761",
   "metadata": {},
   "source": [
    "### Fixing number of nodes and layers, varying activation function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d08de5",
   "metadata": {},
   "source": [
    "#### Early stopping of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61512402",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = callbacks.EarlyStopping(\n",
    "    min_delta=0.001,\n",
    "    patience=20, \n",
    "    restore_best_weights=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895ad744",
   "metadata": {},
   "source": [
    "#### 5 layers and 64 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7cc3d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6897 - accuracy: 0.6573 - val_loss: 0.6956 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 0.6844 - accuracy: 0.7138 - val_loss: 0.6980 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 0.6797 - accuracy: 0.7158 - val_loss: 0.7005 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6748 - accuracy: 0.7158 - val_loss: 0.7031 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6701 - accuracy: 0.7158 - val_loss: 0.7058 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6658 - accuracy: 0.7158 - val_loss: 0.7086 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6616 - accuracy: 0.7158 - val_loss: 0.7114 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6575 - accuracy: 0.7158 - val_loss: 0.7144 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6543 - accuracy: 0.7158 - val_loss: 0.7174 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 7ms/step - loss: 0.6498 - accuracy: 0.7158 - val_loss: 0.7206 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6475 - accuracy: 0.7158 - val_loss: 0.7236 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6443 - accuracy: 0.7158 - val_loss: 0.7267 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6410 - accuracy: 0.7158 - val_loss: 0.7300 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      " 59/154 [==========>...................] - ETA: 0s - loss: 0.6361 - accuracy: 0.7293"
     ]
    }
   ],
   "source": [
    "for activation in ['softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 8 layers, 128 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "07d7419c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6913 - accuracy: 0.7154 - val_loss: 0.6945 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6775 - accuracy: 0.7158 - val_loss: 0.6922 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5708 - accuracy: 0.7158 - val_loss: 0.6734 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4258 - accuracy: 0.7158 - val_loss: 0.6578 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.7329 - val_loss: 0.6516 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8090 - val_loss: 0.6443 - val_accuracy: 0.7449\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8683 - val_loss: 0.6342 - val_accuracy: 0.7351\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8842 - val_loss: 0.6187 - val_accuracy: 0.7229\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8858 - val_loss: 0.6016 - val_accuracy: 0.7009\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8844 - val_loss: 0.5896 - val_accuracy: 0.7009\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8907 - val_loss: 0.5930 - val_accuracy: 0.6895\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8922 - val_loss: 0.6044 - val_accuracy: 0.6854\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8934 - val_loss: 0.6227 - val_accuracy: 0.6846\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8909 - val_loss: 0.6358 - val_accuracy: 0.6879\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.8926 - val_loss: 0.6496 - val_accuracy: 0.6895\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2763 - accuracy: 0.8930 - val_loss: 0.6617 - val_accuracy: 0.6936\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2611 - accuracy: 0.8972 - val_loss: 0.6759 - val_accuracy: 0.6944\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.8983 - val_loss: 0.6952 - val_accuracy: 0.6895\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2590 - accuracy: 0.8956 - val_loss: 0.7074 - val_accuracy: 0.6936\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2647 - accuracy: 0.8966 - val_loss: 0.7176 - val_accuracy: 0.6919\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8962 - val_loss: 0.7218 - val_accuracy: 0.6968\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2594 - accuracy: 0.8972 - val_loss: 0.7446 - val_accuracy: 0.6952\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.8972 - val_loss: 0.7508 - val_accuracy: 0.6919\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2643 - accuracy: 0.8989 - val_loss: 0.7562 - val_accuracy: 0.6952\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2632 - accuracy: 0.8985 - val_loss: 0.7629 - val_accuracy: 0.6936\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2512 - accuracy: 0.8997 - val_loss: 0.7659 - val_accuracy: 0.6968\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2598 - accuracy: 0.8997 - val_loss: 0.7782 - val_accuracy: 0.6976\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2611 - accuracy: 0.9003 - val_loss: 0.7779 - val_accuracy: 0.6952\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.9009 - val_loss: 0.7821 - val_accuracy: 0.6927\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2580 - accuracy: 0.8987 - val_loss: 0.7788 - val_accuracy: 0.6968\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 5 layers, 64 nodes initially with activation function relu : 0.6952054794520548\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6902 - accuracy: 0.7160 - val_loss: 0.6926 - val_accuracy: 0.4360\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6382 - accuracy: 0.8563 - val_loss: 0.6439 - val_accuracy: 0.7506\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.9015 - val_loss: 0.6040 - val_accuracy: 0.7139\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4649 - accuracy: 0.9093 - val_loss: 0.5960 - val_accuracy: 0.6919\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.9103 - val_loss: 0.5989 - val_accuracy: 0.6813\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3971 - accuracy: 0.9131 - val_loss: 0.6033 - val_accuracy: 0.6797\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3786 - accuracy: 0.9127 - val_loss: 0.6061 - val_accuracy: 0.6797\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.9146 - val_loss: 0.6182 - val_accuracy: 0.6748\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3457 - accuracy: 0.9168 - val_loss: 0.6282 - val_accuracy: 0.6699\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.9148 - val_loss: 0.6423 - val_accuracy: 0.6675\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3315 - accuracy: 0.9152 - val_loss: 0.6504 - val_accuracy: 0.6683\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.9146 - val_loss: 0.6579 - val_accuracy: 0.6675\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.9140 - val_loss: 0.6666 - val_accuracy: 0.6707\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.9148 - val_loss: 0.6735 - val_accuracy: 0.6691\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.9158 - val_loss: 0.6887 - val_accuracy: 0.6659\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2976 - accuracy: 0.9162 - val_loss: 0.7029 - val_accuracy: 0.6650\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2966 - accuracy: 0.9150 - val_loss: 0.7005 - val_accuracy: 0.6683\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2879 - accuracy: 0.9166 - val_loss: 0.7106 - val_accuracy: 0.6683\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9164 - val_loss: 0.7155 - val_accuracy: 0.6683\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9166 - val_loss: 0.7155 - val_accuracy: 0.6707\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9160 - val_loss: 0.7174 - val_accuracy: 0.6691\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2753 - accuracy: 0.9170 - val_loss: 0.7264 - val_accuracy: 0.6675\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2727 - accuracy: 0.9172 - val_loss: 0.7314 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2707 - accuracy: 0.9176 - val_loss: 0.7272 - val_accuracy: 0.6716\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 5 layers, 64 nodes initially with activation function tanh : 0.7127092846270928\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.7231 - val_loss: 0.6899 - val_accuracy: 0.6072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.5848 - accuracy: 0.8869 - val_loss: 0.6062 - val_accuracy: 0.7180\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.3851 - accuracy: 0.9054 - val_loss: 0.5959 - val_accuracy: 0.6846\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2941 - accuracy: 0.9078 - val_loss: 0.6343 - val_accuracy: 0.6764\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2693 - accuracy: 0.9103 - val_loss: 0.6826 - val_accuracy: 0.6707\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2624 - accuracy: 0.9115 - val_loss: 0.7214 - val_accuracy: 0.6626\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2552 - accuracy: 0.9125 - val_loss: 0.7489 - val_accuracy: 0.6585\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2527 - accuracy: 0.9121 - val_loss: 0.7748 - val_accuracy: 0.6553\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2531 - accuracy: 0.9136 - val_loss: 0.7863 - val_accuracy: 0.6601\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2503 - accuracy: 0.9136 - val_loss: 0.7957 - val_accuracy: 0.6626\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2480 - accuracy: 0.9140 - val_loss: 0.8035 - val_accuracy: 0.6667\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2463 - accuracy: 0.9154 - val_loss: 0.8039 - val_accuracy: 0.6683\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2487 - accuracy: 0.9158 - val_loss: 0.8127 - val_accuracy: 0.6683\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2488 - accuracy: 0.9150 - val_loss: 0.8216 - val_accuracy: 0.6691\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 2ms/step - loss: 0.2478 - accuracy: 0.9156 - val_loss: 0.8084 - val_accuracy: 0.6716\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2454 - accuracy: 0.9164 - val_loss: 0.8241 - val_accuracy: 0.6707\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2458 - accuracy: 0.9166 - val_loss: 0.8296 - val_accuracy: 0.6707\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2433 - accuracy: 0.9160 - val_loss: 0.8315 - val_accuracy: 0.6724\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2437 - accuracy: 0.9180 - val_loss: 0.8314 - val_accuracy: 0.6724\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2443 - accuracy: 0.9170 - val_loss: 0.8223 - val_accuracy: 0.6740\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2406 - accuracy: 0.9166 - val_loss: 0.8267 - val_accuracy: 0.6740\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2426 - accuracy: 0.9182 - val_loss: 0.8380 - val_accuracy: 0.6716\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2425 - accuracy: 0.9176 - val_loss: 0.8310 - val_accuracy: 0.6740\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 5 layers, 64 nodes initially with activation function selu : 0.7077625570776256\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.6890 - accuracy: 0.6866 - val_loss: 0.6960 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6839 - accuracy: 0.7158 - val_loss: 0.6984 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6788 - accuracy: 0.7158 - val_loss: 0.7009 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6741 - accuracy: 0.7158 - val_loss: 0.7035 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6696 - accuracy: 0.7158 - val_loss: 0.7062 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6649 - accuracy: 0.7158 - val_loss: 0.7091 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6607 - accuracy: 0.7158 - val_loss: 0.7119 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6572 - accuracy: 0.7158 - val_loss: 0.7149 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6533 - accuracy: 0.7158 - val_loss: 0.7179 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6507 - accuracy: 0.7158 - val_loss: 0.7210 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6464 - accuracy: 0.7158 - val_loss: 0.7242 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.7158 - val_loss: 0.7273 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6415 - accuracy: 0.7158 - val_loss: 0.7305 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6374 - accuracy: 0.7158 - val_loss: 0.7339 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7158 - val_loss: 0.7372 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6331 - accuracy: 0.7158 - val_loss: 0.7404 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6309 - accuracy: 0.7158 - val_loss: 0.7438 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6283 - accuracy: 0.7158 - val_loss: 0.7471 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6259 - accuracy: 0.7158 - val_loss: 0.7506 - val_accuracy: 0.4156\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6248 - accuracy: 0.7158 - val_loss: 0.7539 - val_accuracy: 0.4156\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6225 - accuracy: 0.7158 - val_loss: 0.7573 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 5 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 5 layers, 64 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c22695",
   "metadata": {},
   "source": [
    "#### 8 layers and 64 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cc7fb278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6917 - accuracy: 0.7158 - val_loss: 0.6943 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6887 - accuracy: 0.7158 - val_loss: 0.6957 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6849 - accuracy: 0.7158 - val_loss: 0.6978 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.7158 - val_loss: 0.6973 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7158 - val_loss: 0.6699 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4021 - accuracy: 0.7158 - val_loss: 0.6640 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3931 - accuracy: 0.7158 - val_loss: 0.6624 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3827 - accuracy: 0.7158 - val_loss: 0.6608 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3897 - accuracy: 0.7158 - val_loss: 0.6597 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3855 - accuracy: 0.7158 - val_loss: 0.6592 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3830 - accuracy: 0.7158 - val_loss: 0.6582 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.7164 - val_loss: 0.6550 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8016 - val_loss: 0.6509 - val_accuracy: 0.7099\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8622 - val_loss: 0.6492 - val_accuracy: 0.7099\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3705 - accuracy: 0.8606 - val_loss: 0.6460 - val_accuracy: 0.7033\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3673 - accuracy: 0.8642 - val_loss: 0.6412 - val_accuracy: 0.6895\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8385 - val_loss: 0.6344 - val_accuracy: 0.6903\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3572 - accuracy: 0.8361 - val_loss: 0.6246 - val_accuracy: 0.6846\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3475 - accuracy: 0.8412 - val_loss: 0.6133 - val_accuracy: 0.6822\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3368 - accuracy: 0.8404 - val_loss: 0.6048 - val_accuracy: 0.6748\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.8373 - val_loss: 0.6034 - val_accuracy: 0.6764\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3159 - accuracy: 0.8389 - val_loss: 0.6192 - val_accuracy: 0.6740\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3148 - accuracy: 0.8351 - val_loss: 0.6215 - val_accuracy: 0.6879\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.3086 - accuracy: 0.8391 - val_loss: 0.6409 - val_accuracy: 0.6879\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2971 - accuracy: 0.8418 - val_loss: 0.6703 - val_accuracy: 0.6830\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3033 - accuracy: 0.8410 - val_loss: 0.6876 - val_accuracy: 0.6813\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3015 - accuracy: 0.8463 - val_loss: 0.6699 - val_accuracy: 0.6936\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3007 - accuracy: 0.8367 - val_loss: 0.6857 - val_accuracy: 0.6911\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2964 - accuracy: 0.8446 - val_loss: 0.7103 - val_accuracy: 0.6854\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8958 - val_loss: 0.6995 - val_accuracy: 0.6919\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3078 - accuracy: 0.9085 - val_loss: 0.7074 - val_accuracy: 0.6887\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.9109 - val_loss: 0.7048 - val_accuracy: 0.6919\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2930 - accuracy: 0.9083 - val_loss: 0.7286 - val_accuracy: 0.6879\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.2974 - accuracy: 0.9056 - val_loss: 0.7237 - val_accuracy: 0.6927\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2976 - accuracy: 0.9109 - val_loss: 0.7291 - val_accuracy: 0.6927\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2947 - accuracy: 0.9076 - val_loss: 0.7401 - val_accuracy: 0.6903\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2926 - accuracy: 0.9089 - val_loss: 0.7492 - val_accuracy: 0.6879\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.9083 - val_loss: 0.7271 - val_accuracy: 0.6976\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.9068 - val_loss: 0.7348 - val_accuracy: 0.6952\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2885 - accuracy: 0.9074 - val_loss: 0.7340 - val_accuracy: 0.6960\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2953 - accuracy: 0.9095 - val_loss: 0.7288 - val_accuracy: 0.6968\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function relu : 0.7165144596651446\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6913 - accuracy: 0.7160 - val_loss: 0.6947 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6812 - accuracy: 0.7217 - val_loss: 0.6850 - val_accuracy: 0.5941\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.5923 - accuracy: 0.8922 - val_loss: 0.6306 - val_accuracy: 0.7148\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.9123 - val_loss: 0.6151 - val_accuracy: 0.6952\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4591 - accuracy: 0.9156 - val_loss: 0.6083 - val_accuracy: 0.6919\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4237 - accuracy: 0.9152 - val_loss: 0.6107 - val_accuracy: 0.6822\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3990 - accuracy: 0.9170 - val_loss: 0.6111 - val_accuracy: 0.6862\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3790 - accuracy: 0.9174 - val_loss: 0.6049 - val_accuracy: 0.7017\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3654 - accuracy: 0.9174 - val_loss: 0.6157 - val_accuracy: 0.6911\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.9170 - val_loss: 0.6218 - val_accuracy: 0.6895\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3395 - accuracy: 0.9170 - val_loss: 0.6230 - val_accuracy: 0.6944\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.9172 - val_loss: 0.6358 - val_accuracy: 0.6862\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.9176 - val_loss: 0.6395 - val_accuracy: 0.6879\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.9176 - val_loss: 0.6442 - val_accuracy: 0.6895\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.9187 - val_loss: 0.6527 - val_accuracy: 0.6903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.9180 - val_loss: 0.6525 - val_accuracy: 0.6911\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.9178 - val_loss: 0.6528 - val_accuracy: 0.6911\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.9174 - val_loss: 0.6637 - val_accuracy: 0.6838\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.9176 - val_loss: 0.6663 - val_accuracy: 0.6846\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.9166 - val_loss: 0.6709 - val_accuracy: 0.6773\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.9158 - val_loss: 0.6791 - val_accuracy: 0.6732\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.9166 - val_loss: 0.6973 - val_accuracy: 0.6683\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.9162 - val_loss: 0.7082 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.9152 - val_loss: 0.7053 - val_accuracy: 0.6691\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.9158 - val_loss: 0.7195 - val_accuracy: 0.6683\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.9178 - val_loss: 0.7228 - val_accuracy: 0.6683\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.9158 - val_loss: 0.7233 - val_accuracy: 0.6691\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.9154 - val_loss: 0.7222 - val_accuracy: 0.6716\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function tanh : 0.719558599695586\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6904 - accuracy: 0.7154 - val_loss: 0.6949 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6192 - accuracy: 0.8314 - val_loss: 0.6218 - val_accuracy: 0.7302\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4420 - accuracy: 0.9076 - val_loss: 0.5981 - val_accuracy: 0.6887\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3467 - accuracy: 0.9099 - val_loss: 0.6478 - val_accuracy: 0.6903\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.9121 - val_loss: 0.7116 - val_accuracy: 0.6822\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.9168 - val_loss: 0.7456 - val_accuracy: 0.6895\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.9170 - val_loss: 0.7757 - val_accuracy: 0.6927\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.9174 - val_loss: 0.7923 - val_accuracy: 0.6862\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.9176 - val_loss: 0.7898 - val_accuracy: 0.6919\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2884 - accuracy: 0.9176 - val_loss: 0.7867 - val_accuracy: 0.6960\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.9180 - val_loss: 0.7956 - val_accuracy: 0.6903\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2902 - accuracy: 0.9166 - val_loss: 0.7759 - val_accuracy: 0.6952\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.9195 - val_loss: 0.7988 - val_accuracy: 0.6927\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.9174 - val_loss: 0.7963 - val_accuracy: 0.6936\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2794 - accuracy: 0.9174 - val_loss: 0.7920 - val_accuracy: 0.6952\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.9189 - val_loss: 0.7933 - val_accuracy: 0.6862\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.9189 - val_loss: 0.8112 - val_accuracy: 0.6805\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.9170 - val_loss: 0.7936 - val_accuracy: 0.6862\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.9168 - val_loss: 0.8249 - val_accuracy: 0.6789\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.9164 - val_loss: 0.8482 - val_accuracy: 0.6748\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.9156 - val_loss: 0.8636 - val_accuracy: 0.6740\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.9166 - val_loss: 0.8986 - val_accuracy: 0.6699\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.9168 - val_loss: 0.9077 - val_accuracy: 0.6683\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function selu : 0.7111872146118722\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6923 - accuracy: 0.5584 - val_loss: 0.6946 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6868 - accuracy: 0.7158 - val_loss: 0.6969 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6819 - accuracy: 0.7158 - val_loss: 0.6993 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6770 - accuracy: 0.7158 - val_loss: 0.7018 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7158 - val_loss: 0.7044 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.7158 - val_loss: 0.7072 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6638 - accuracy: 0.7158 - val_loss: 0.7099 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6599 - accuracy: 0.7158 - val_loss: 0.7128 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6563 - accuracy: 0.7158 - val_loss: 0.7158 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6524 - accuracy: 0.7158 - val_loss: 0.7188 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6492 - accuracy: 0.7158 - val_loss: 0.7219 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6461 - accuracy: 0.7158 - val_loss: 0.7250 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6429 - accuracy: 0.7158 - val_loss: 0.7281 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6405 - accuracy: 0.7158 - val_loss: 0.7313 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6372 - accuracy: 0.7158 - val_loss: 0.7345 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6343 - accuracy: 0.7158 - val_loss: 0.7378 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6321 - accuracy: 0.7158 - val_loss: 0.7411 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6298 - accuracy: 0.7158 - val_loss: 0.7445 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.7158 - val_loss: 0.7479 - val_accuracy: 0.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6268 - accuracy: 0.7158 - val_loss: 0.7511 - val_accuracy: 0.4156\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6235 - accuracy: 0.7158 - val_loss: 0.7545 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 8 layers, 64 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e99b21",
   "metadata": {},
   "source": [
    "#### 8 layers and 128 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "842a0800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.7156 - val_loss: 0.6944 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6882 - accuracy: 0.7158 - val_loss: 0.6961 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6382 - accuracy: 0.7158 - val_loss: 0.6782 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4044 - accuracy: 0.7158 - val_loss: 0.6570 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.7158 - val_loss: 0.6550 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3862 - accuracy: 0.7158 - val_loss: 0.6576 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3826 - accuracy: 0.7757 - val_loss: 0.6525 - val_accuracy: 0.7302\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3829 - accuracy: 0.8100 - val_loss: 0.6457 - val_accuracy: 0.7115\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3744 - accuracy: 0.8106 - val_loss: 0.6244 - val_accuracy: 0.7050\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3481 - accuracy: 0.8124 - val_loss: 0.5943 - val_accuracy: 0.6927\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3261 - accuracy: 0.8206 - val_loss: 0.5958 - val_accuracy: 0.6838\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3201 - accuracy: 0.8165 - val_loss: 0.6050 - val_accuracy: 0.6854\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8175 - val_loss: 0.6025 - val_accuracy: 0.6993\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3177 - accuracy: 0.8224 - val_loss: 0.6184 - val_accuracy: 0.6846\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3151 - accuracy: 0.8202 - val_loss: 0.6218 - val_accuracy: 0.6968\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8126 - val_loss: 0.6333 - val_accuracy: 0.6846\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8206 - val_loss: 0.6182 - val_accuracy: 0.7009\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8285 - val_loss: 0.6189 - val_accuracy: 0.7050\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8173 - val_loss: 0.6110 - val_accuracy: 0.7066\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8147 - val_loss: 0.6179 - val_accuracy: 0.6985\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8234 - val_loss: 0.6198 - val_accuracy: 0.7009\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8243 - val_loss: 0.6219 - val_accuracy: 0.6993\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8202 - val_loss: 0.6145 - val_accuracy: 0.7058\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8267 - val_loss: 0.6173 - val_accuracy: 0.7058\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3242 - accuracy: 0.8110 - val_loss: 0.6222 - val_accuracy: 0.6985\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3213 - accuracy: 0.8285 - val_loss: 0.6128 - val_accuracy: 0.7058\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3179 - accuracy: 0.8434 - val_loss: 0.6146 - val_accuracy: 0.7050\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3218 - accuracy: 0.8402 - val_loss: 0.6151 - val_accuracy: 0.7033\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8414 - val_loss: 0.6155 - val_accuracy: 0.7058\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3222 - accuracy: 0.8412 - val_loss: 0.6185 - val_accuracy: 0.6985\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function relu : 0.6993911719939118\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6905 - accuracy: 0.7150 - val_loss: 0.6935 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5965 - accuracy: 0.8789 - val_loss: 0.6225 - val_accuracy: 0.7107\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4975 - accuracy: 0.9107 - val_loss: 0.6098 - val_accuracy: 0.6985\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4528 - accuracy: 0.9156 - val_loss: 0.6148 - val_accuracy: 0.6838\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4178 - accuracy: 0.9146 - val_loss: 0.6137 - val_accuracy: 0.6895\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3976 - accuracy: 0.9170 - val_loss: 0.6205 - val_accuracy: 0.6797\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.9158 - val_loss: 0.6200 - val_accuracy: 0.6862\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3683 - accuracy: 0.9156 - val_loss: 0.6140 - val_accuracy: 0.6985\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.9164 - val_loss: 0.6203 - val_accuracy: 0.6903\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.9176 - val_loss: 0.6158 - val_accuracy: 0.7017\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.9166 - val_loss: 0.6168 - val_accuracy: 0.6944\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.9164 - val_loss: 0.6206 - val_accuracy: 0.6895\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3215 - accuracy: 0.9172 - val_loss: 0.6289 - val_accuracy: 0.6846\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.9168 - val_loss: 0.6534 - val_accuracy: 0.6740\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3090 - accuracy: 0.9142 - val_loss: 0.6651 - val_accuracy: 0.6699\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.9170 - val_loss: 0.6785 - val_accuracy: 0.6724\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2984 - accuracy: 0.9160 - val_loss: 0.6981 - val_accuracy: 0.6642\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.9170 - val_loss: 0.6967 - val_accuracy: 0.6683\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.9142 - val_loss: 0.6889 - val_accuracy: 0.6732\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.9178 - val_loss: 0.6774 - val_accuracy: 0.6756\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.9162 - val_loss: 0.7045 - val_accuracy: 0.6699\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.9158 - val_loss: 0.6946 - val_accuracy: 0.6764\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.9146 - val_loss: 0.6915 - val_accuracy: 0.6764\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function tanh : 0.7146118721461188\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6847 - accuracy: 0.7370 - val_loss: 0.6747 - val_accuracy: 0.7115\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.9040 - val_loss: 0.6170 - val_accuracy: 0.6781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.9113 - val_loss: 0.7517 - val_accuracy: 0.6659\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.9109 - val_loss: 0.8256 - val_accuracy: 0.6585\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.9119 - val_loss: 0.8283 - val_accuracy: 0.6650\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.9146 - val_loss: 0.8455 - val_accuracy: 0.6650\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2718 - accuracy: 0.9150 - val_loss: 0.8420 - val_accuracy: 0.6699\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.9156 - val_loss: 0.8545 - val_accuracy: 0.6618\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9148 - val_loss: 0.8637 - val_accuracy: 0.6634\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2720 - accuracy: 0.9138 - val_loss: 0.8719 - val_accuracy: 0.6569\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2609 - accuracy: 0.9156 - val_loss: 0.8703 - val_accuracy: 0.6634\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2697 - accuracy: 0.9154 - val_loss: 0.8216 - val_accuracy: 0.6683\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2598 - accuracy: 0.9156 - val_loss: 0.8700 - val_accuracy: 0.6659\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.9160 - val_loss: 0.8968 - val_accuracy: 0.6683\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2552 - accuracy: 0.9172 - val_loss: 0.8864 - val_accuracy: 0.6691\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2461 - accuracy: 0.9180 - val_loss: 0.9965 - val_accuracy: 0.6667\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.9156 - val_loss: 0.8946 - val_accuracy: 0.6724\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2534 - accuracy: 0.9162 - val_loss: 1.0062 - val_accuracy: 0.6569\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2460 - accuracy: 0.9144 - val_loss: 0.9845 - val_accuracy: 0.6691\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2396 - accuracy: 0.9178 - val_loss: 0.9511 - val_accuracy: 0.6764\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.2432 - accuracy: 0.9176 - val_loss: 1.0363 - val_accuracy: 0.6634\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2438 - accuracy: 0.9174 - val_loss: 1.0079 - val_accuracy: 0.6740\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function selu : 0.7104261796042618\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6912 - accuracy: 0.6206 - val_loss: 0.6951 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6859 - accuracy: 0.7158 - val_loss: 0.6974 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6813 - accuracy: 0.7158 - val_loss: 0.6997 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6763 - accuracy: 0.7158 - val_loss: 0.7023 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6718 - accuracy: 0.7158 - val_loss: 0.7049 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6676 - accuracy: 0.7158 - val_loss: 0.7076 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6634 - accuracy: 0.7158 - val_loss: 0.7104 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6595 - accuracy: 0.7158 - val_loss: 0.7133 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6548 - accuracy: 0.7158 - val_loss: 0.7163 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.6524 - accuracy: 0.7158 - val_loss: 0.7193 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6488 - accuracy: 0.7158 - val_loss: 0.7225 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.6453 - accuracy: 0.7158 - val_loss: 0.7256 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6424 - accuracy: 0.7158 - val_loss: 0.7288 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6397 - accuracy: 0.7158 - val_loss: 0.7321 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6371 - accuracy: 0.7158 - val_loss: 0.7354 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6342 - accuracy: 0.7158 - val_loss: 0.7387 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6319 - accuracy: 0.7158 - val_loss: 0.7421 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.7158 - val_loss: 0.7454 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6274 - accuracy: 0.7158 - val_loss: 0.7488 - val_accuracy: 0.4156\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6247 - accuracy: 0.7158 - val_loss: 0.7522 - val_accuracy: 0.4156\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6233 - accuracy: 0.7158 - val_loss: 0.7557 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 8 layers, 128 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a793fa2",
   "metadata": {},
   "source": [
    "#### 12 layers and 64 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c9446ca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 4s 5ms/step - loss: 0.6916 - accuracy: 0.7158 - val_loss: 0.6944 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6882 - accuracy: 0.7158 - val_loss: 0.6960 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6844 - accuracy: 0.7158 - val_loss: 0.6979 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6799 - accuracy: 0.7158 - val_loss: 0.7005 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6738 - accuracy: 0.7158 - val_loss: 0.7045 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6555 - accuracy: 0.7158 - val_loss: 0.7147 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4371 - accuracy: 0.7158 - val_loss: 0.6939 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3800 - accuracy: 0.7158 - val_loss: 0.6830 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3772 - accuracy: 0.7158 - val_loss: 0.6768 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3769 - accuracy: 0.7158 - val_loss: 0.6710 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3642 - accuracy: 0.7158 - val_loss: 0.6662 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3693 - accuracy: 0.7158 - val_loss: 0.6640 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3696 - accuracy: 0.7158 - val_loss: 0.6624 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3634 - accuracy: 0.7158 - val_loss: 0.6597 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.7158 - val_loss: 0.6579 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3564 - accuracy: 0.7158 - val_loss: 0.6572 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3524 - accuracy: 0.7158 - val_loss: 0.6567 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3623 - accuracy: 0.8122 - val_loss: 0.6544 - val_accuracy: 0.7066\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3541 - accuracy: 0.8813 - val_loss: 0.6549 - val_accuracy: 0.6911\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3533 - accuracy: 0.8773 - val_loss: 0.6535 - val_accuracy: 0.6968\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3527 - accuracy: 0.8789 - val_loss: 0.6533 - val_accuracy: 0.6919\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3515 - accuracy: 0.8824 - val_loss: 0.6524 - val_accuracy: 0.6911\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3447 - accuracy: 0.8864 - val_loss: 0.6516 - val_accuracy: 0.6944\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3511 - accuracy: 0.8795 - val_loss: 0.6507 - val_accuracy: 0.6936\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3507 - accuracy: 0.8848 - val_loss: 0.6501 - val_accuracy: 0.6919\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3456 - accuracy: 0.8873 - val_loss: 0.6489 - val_accuracy: 0.6952\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3481 - accuracy: 0.8750 - val_loss: 0.6493 - val_accuracy: 0.6830\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3460 - accuracy: 0.8809 - val_loss: 0.6474 - val_accuracy: 0.6960\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3415 - accuracy: 0.8803 - val_loss: 0.6481 - val_accuracy: 0.6854\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3410 - accuracy: 0.8850 - val_loss: 0.6480 - val_accuracy: 0.6854\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.8818 - val_loss: 0.6481 - val_accuracy: 0.6789\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.8828 - val_loss: 0.6471 - val_accuracy: 0.6805\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3393 - accuracy: 0.8805 - val_loss: 0.6471 - val_accuracy: 0.6781\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3367 - accuracy: 0.8848 - val_loss: 0.6468 - val_accuracy: 0.6764\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3320 - accuracy: 0.8852 - val_loss: 0.6461 - val_accuracy: 0.6781\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3453 - accuracy: 0.8815 - val_loss: 0.6450 - val_accuracy: 0.6822\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3418 - accuracy: 0.8783 - val_loss: 0.6452 - val_accuracy: 0.6773\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3338 - accuracy: 0.8871 - val_loss: 0.6445 - val_accuracy: 0.6797\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3407 - accuracy: 0.8777 - val_loss: 0.6440 - val_accuracy: 0.6830\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3362 - accuracy: 0.8834 - val_loss: 0.6435 - val_accuracy: 0.6830\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3396 - accuracy: 0.8787 - val_loss: 0.6434 - val_accuracy: 0.6781\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3326 - accuracy: 0.8822 - val_loss: 0.6445 - val_accuracy: 0.6756\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3319 - accuracy: 0.8826 - val_loss: 0.6443 - val_accuracy: 0.6748\n",
      "Epoch 44/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8834 - val_loss: 0.6431 - val_accuracy: 0.6773\n",
      "Epoch 45/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3373 - accuracy: 0.8811 - val_loss: 0.6419 - val_accuracy: 0.6805\n",
      "Epoch 46/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3304 - accuracy: 0.8862 - val_loss: 0.6427 - val_accuracy: 0.6789\n",
      "Epoch 47/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3343 - accuracy: 0.8769 - val_loss: 0.6433 - val_accuracy: 0.6764\n",
      "Epoch 48/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8813 - val_loss: 0.6426 - val_accuracy: 0.6789\n",
      "Epoch 49/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3271 - accuracy: 0.8856 - val_loss: 0.6442 - val_accuracy: 0.6748\n",
      "Epoch 50/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8846 - val_loss: 0.6451 - val_accuracy: 0.6748\n",
      "Epoch 51/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8852 - val_loss: 0.6453 - val_accuracy: 0.6748\n",
      "Epoch 52/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8844 - val_loss: 0.6438 - val_accuracy: 0.6764\n",
      "Epoch 53/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3293 - accuracy: 0.8789 - val_loss: 0.6438 - val_accuracy: 0.6773\n",
      "Epoch 54/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8791 - val_loss: 0.6428 - val_accuracy: 0.6756\n",
      "Epoch 55/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8850 - val_loss: 0.6426 - val_accuracy: 0.6773\n",
      "Epoch 56/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8771 - val_loss: 0.6429 - val_accuracy: 0.6773\n",
      "Epoch 57/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8803 - val_loss: 0.6428 - val_accuracy: 0.6773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8811 - val_loss: 0.6415 - val_accuracy: 0.6789\n",
      "Epoch 59/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8866 - val_loss: 0.6415 - val_accuracy: 0.6789\n",
      "Epoch 60/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8775 - val_loss: 0.6437 - val_accuracy: 0.6773\n",
      "Epoch 61/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8799 - val_loss: 0.6432 - val_accuracy: 0.6764\n",
      "Epoch 62/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8836 - val_loss: 0.6436 - val_accuracy: 0.6764\n",
      "Epoch 63/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8830 - val_loss: 0.6453 - val_accuracy: 0.6748\n",
      "Epoch 64/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8815 - val_loss: 0.6452 - val_accuracy: 0.6764\n",
      "Epoch 65/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8826 - val_loss: 0.6446 - val_accuracy: 0.6764\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function relu : 0.6959665144596652\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.6916 - accuracy: 0.7158 - val_loss: 0.6945 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6878 - accuracy: 0.7158 - val_loss: 0.6965 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6809 - accuracy: 0.7158 - val_loss: 0.7017 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6470 - accuracy: 0.7627 - val_loss: 0.6687 - val_accuracy: 0.7196\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5759 - accuracy: 0.9021 - val_loss: 0.6496 - val_accuracy: 0.6764\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5324 - accuracy: 0.9131 - val_loss: 0.6376 - val_accuracy: 0.6805\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.5000 - accuracy: 0.9162 - val_loss: 0.6250 - val_accuracy: 0.6919\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4758 - accuracy: 0.9170 - val_loss: 0.6145 - val_accuracy: 0.6985\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.9195 - val_loss: 0.6167 - val_accuracy: 0.6895\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4399 - accuracy: 0.9152 - val_loss: 0.6215 - val_accuracy: 0.6781\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4234 - accuracy: 0.9158 - val_loss: 0.6212 - val_accuracy: 0.6781\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4102 - accuracy: 0.9156 - val_loss: 0.6270 - val_accuracy: 0.6724\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3980 - accuracy: 0.9176 - val_loss: 0.6183 - val_accuracy: 0.6838\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3883 - accuracy: 0.9144 - val_loss: 0.6187 - val_accuracy: 0.6862\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3795 - accuracy: 0.9166 - val_loss: 0.6209 - val_accuracy: 0.6854\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.9170 - val_loss: 0.6349 - val_accuracy: 0.6740\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3614 - accuracy: 0.9176 - val_loss: 0.6402 - val_accuracy: 0.6707\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.9185 - val_loss: 0.6400 - val_accuracy: 0.6740\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.9182 - val_loss: 0.6410 - val_accuracy: 0.6781\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.9178 - val_loss: 0.6454 - val_accuracy: 0.6748\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.9180 - val_loss: 0.6445 - val_accuracy: 0.6789\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3314 - accuracy: 0.9180 - val_loss: 0.6461 - val_accuracy: 0.6813\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3244 - accuracy: 0.9199 - val_loss: 0.6588 - val_accuracy: 0.6740\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.9185 - val_loss: 0.6606 - val_accuracy: 0.6764\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3158 - accuracy: 0.9201 - val_loss: 0.6536 - val_accuracy: 0.6838\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.9187 - val_loss: 0.6711 - val_accuracy: 0.6748\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3096 - accuracy: 0.9191 - val_loss: 0.6757 - val_accuracy: 0.6732\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3067 - accuracy: 0.9182 - val_loss: 0.6724 - val_accuracy: 0.6797\n",
      "83/83 [==============================] - 0s 1ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function tanh : 0.7184170471841704\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.6911 - accuracy: 0.7158 - val_loss: 0.6950 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6842 - accuracy: 0.7158 - val_loss: 0.7003 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6108 - accuracy: 0.8292 - val_loss: 0.6330 - val_accuracy: 0.6870\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.4788 - accuracy: 0.9115 - val_loss: 0.5911 - val_accuracy: 0.7131\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3978 - accuracy: 0.9154 - val_loss: 0.7384 - val_accuracy: 0.6748\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.9174 - val_loss: 0.8318 - val_accuracy: 0.6748\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.9158 - val_loss: 0.8885 - val_accuracy: 0.6724\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.9148 - val_loss: 0.8802 - val_accuracy: 0.6789\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.9170 - val_loss: 0.9158 - val_accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3068 - accuracy: 0.9174 - val_loss: 0.8070 - val_accuracy: 0.7017\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.9164 - val_loss: 0.8432 - val_accuracy: 0.6911\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.9187 - val_loss: 0.8350 - val_accuracy: 0.7001\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.9170 - val_loss: 0.8623 - val_accuracy: 0.6919\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.9201 - val_loss: 0.8921 - val_accuracy: 0.6879\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.9172 - val_loss: 0.9337 - val_accuracy: 0.6716\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.9180 - val_loss: 0.9138 - val_accuracy: 0.6732\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.9182 - val_loss: 0.9001 - val_accuracy: 0.6756\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.9185 - val_loss: 0.9145 - val_accuracy: 0.6740\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.9185 - val_loss: 0.9259 - val_accuracy: 0.6716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.9178 - val_loss: 0.9058 - val_accuracy: 0.6716\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.9193 - val_loss: 0.8933 - val_accuracy: 0.6830\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.9180 - val_loss: 0.9040 - val_accuracy: 0.6756\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.9176 - val_loss: 0.9129 - val_accuracy: 0.6813\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.9189 - val_loss: 0.9062 - val_accuracy: 0.6813\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function selu : 0.7214611872146118\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 4ms/step - loss: 0.6935 - accuracy: 0.4703 - val_loss: 0.6941 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6879 - accuracy: 0.7158 - val_loss: 0.6965 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6825 - accuracy: 0.7158 - val_loss: 0.6990 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6774 - accuracy: 0.7158 - val_loss: 0.7017 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6725 - accuracy: 0.7158 - val_loss: 0.7044 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6679 - accuracy: 0.7158 - val_loss: 0.7073 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6635 - accuracy: 0.7158 - val_loss: 0.7102 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6593 - accuracy: 0.7158 - val_loss: 0.7132 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6553 - accuracy: 0.7158 - val_loss: 0.7164 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6514 - accuracy: 0.7158 - val_loss: 0.7196 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6478 - accuracy: 0.7158 - val_loss: 0.7230 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6444 - accuracy: 0.7158 - val_loss: 0.7263 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6411 - accuracy: 0.7158 - val_loss: 0.7298 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6380 - accuracy: 0.7158 - val_loss: 0.7333 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7158 - val_loss: 0.7369 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6323 - accuracy: 0.7158 - val_loss: 0.7405 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6297 - accuracy: 0.7158 - val_loss: 0.7441 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6272 - accuracy: 0.7158 - val_loss: 0.7478 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6249 - accuracy: 0.7158 - val_loss: 0.7515 - val_accuracy: 0.4156\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6227 - accuracy: 0.7158 - val_loss: 0.7553 - val_accuracy: 0.4156\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 0s 3ms/step - loss: 0.6206 - accuracy: 0.7158 - val_loss: 0.7591 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 12 layers, 64 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12f8313",
   "metadata": {},
   "source": [
    "#### 12 layers and 256 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "43742473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6917 - accuracy: 0.7158 - val_loss: 0.6944 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6886 - accuracy: 0.7158 - val_loss: 0.6958 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6849 - accuracy: 0.7158 - val_loss: 0.6978 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5544 - accuracy: 0.7158 - val_loss: 0.6650 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3609 - accuracy: 0.7158 - val_loss: 0.6626 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3553 - accuracy: 0.7158 - val_loss: 0.6603 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3505 - accuracy: 0.7158 - val_loss: 0.6607 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3483 - accuracy: 0.7158 - val_loss: 0.6612 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3445 - accuracy: 0.7158 - val_loss: 0.6618 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3450 - accuracy: 0.7158 - val_loss: 0.6597 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3381 - accuracy: 0.8204 - val_loss: 0.6590 - val_accuracy: 0.6993\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3396 - accuracy: 0.9007 - val_loss: 0.6583 - val_accuracy: 0.7009\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3374 - accuracy: 0.9003 - val_loss: 0.6607 - val_accuracy: 0.6764\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3313 - accuracy: 0.9089 - val_loss: 0.6589 - val_accuracy: 0.6993\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3347 - accuracy: 0.9019 - val_loss: 0.6608 - val_accuracy: 0.6822\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.9019 - val_loss: 0.6607 - val_accuracy: 0.6862\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3301 - accuracy: 0.9021 - val_loss: 0.6613 - val_accuracy: 0.6797\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3333 - accuracy: 0.9013 - val_loss: 0.6591 - val_accuracy: 0.6846\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3298 - accuracy: 0.9009 - val_loss: 0.6592 - val_accuracy: 0.6781\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3300 - accuracy: 0.8997 - val_loss: 0.6604 - val_accuracy: 0.6724\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3266 - accuracy: 0.9038 - val_loss: 0.6569 - val_accuracy: 0.6716\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3258 - accuracy: 0.8983 - val_loss: 0.6537 - val_accuracy: 0.6740\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3071 - accuracy: 0.9003 - val_loss: 0.6312 - val_accuracy: 0.6667\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2692 - accuracy: 0.8964 - val_loss: 0.7466 - val_accuracy: 0.6675\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2535 - accuracy: 0.9046 - val_loss: 0.8213 - val_accuracy: 0.6740\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2608 - accuracy: 0.9019 - val_loss: 0.7627 - val_accuracy: 0.6756\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2491 - accuracy: 0.9052 - val_loss: 0.7953 - val_accuracy: 0.6830\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2504 - accuracy: 0.9046 - val_loss: 0.8299 - val_accuracy: 0.6789\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2504 - accuracy: 0.9034 - val_loss: 0.7902 - val_accuracy: 0.6919\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2446 - accuracy: 0.9081 - val_loss: 0.8174 - val_accuracy: 0.6830\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2506 - accuracy: 0.9046 - val_loss: 0.8075 - val_accuracy: 0.6822\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.9101 - val_loss: 0.8021 - val_accuracy: 0.6813\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2521 - accuracy: 0.9044 - val_loss: 0.8204 - val_accuracy: 0.6773\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2463 - accuracy: 0.9054 - val_loss: 0.8059 - val_accuracy: 0.6879\n",
      "Epoch 35/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2366 - accuracy: 0.9070 - val_loss: 0.8304 - val_accuracy: 0.6838\n",
      "Epoch 36/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2444 - accuracy: 0.9070 - val_loss: 0.8337 - val_accuracy: 0.6813\n",
      "Epoch 37/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2392 - accuracy: 0.9076 - val_loss: 0.8619 - val_accuracy: 0.6813\n",
      "Epoch 38/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2492 - accuracy: 0.9087 - val_loss: 0.8161 - val_accuracy: 0.7017\n",
      "Epoch 39/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2419 - accuracy: 0.9066 - val_loss: 0.8261 - val_accuracy: 0.6927\n",
      "Epoch 40/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2426 - accuracy: 0.9064 - val_loss: 0.8117 - val_accuracy: 0.6985\n",
      "Epoch 41/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2372 - accuracy: 0.9117 - val_loss: 0.8740 - val_accuracy: 0.6797\n",
      "Epoch 42/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2425 - accuracy: 0.9101 - val_loss: 0.8509 - val_accuracy: 0.6822\n",
      "Epoch 43/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2459 - accuracy: 0.9078 - val_loss: 0.8511 - val_accuracy: 0.6830\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function relu : 0.715372907153729\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6915 - accuracy: 0.7158 - val_loss: 0.6946 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6864 - accuracy: 0.7158 - val_loss: 0.6970 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6302 - accuracy: 0.8815 - val_loss: 0.6624 - val_accuracy: 0.6756\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5769 - accuracy: 0.9150 - val_loss: 0.6477 - val_accuracy: 0.6805\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5401 - accuracy: 0.9142 - val_loss: 0.6418 - val_accuracy: 0.6716\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5121 - accuracy: 0.9164 - val_loss: 0.6153 - val_accuracy: 0.7148\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4884 - accuracy: 0.9154 - val_loss: 0.6214 - val_accuracy: 0.6927\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4686 - accuracy: 0.9119 - val_loss: 0.6399 - val_accuracy: 0.6553\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4536 - accuracy: 0.9097 - val_loss: 0.6321 - val_accuracy: 0.6659\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4354 - accuracy: 0.9123 - val_loss: 0.6344 - val_accuracy: 0.6634\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4208 - accuracy: 0.9142 - val_loss: 0.6248 - val_accuracy: 0.6764\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4075 - accuracy: 0.9162 - val_loss: 0.6341 - val_accuracy: 0.6667\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3987 - accuracy: 0.9117 - val_loss: 0.6503 - val_accuracy: 0.6487\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3889 - accuracy: 0.9123 - val_loss: 0.6446 - val_accuracy: 0.6569\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3797 - accuracy: 0.9148 - val_loss: 0.6358 - val_accuracy: 0.6699\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3724 - accuracy: 0.9138 - val_loss: 0.6325 - val_accuracy: 0.6740\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3626 - accuracy: 0.9148 - val_loss: 0.6398 - val_accuracy: 0.6707\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3574 - accuracy: 0.9140 - val_loss: 0.6421 - val_accuracy: 0.6716\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3471 - accuracy: 0.9172 - val_loss: 0.6488 - val_accuracy: 0.6691\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3413 - accuracy: 0.9172 - val_loss: 0.6301 - val_accuracy: 0.6879\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3364 - accuracy: 0.9164 - val_loss: 0.6314 - val_accuracy: 0.6879\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3304 - accuracy: 0.9185 - val_loss: 0.6372 - val_accuracy: 0.6911\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3262 - accuracy: 0.9189 - val_loss: 0.6430 - val_accuracy: 0.6846\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3202 - accuracy: 0.9195 - val_loss: 0.6469 - val_accuracy: 0.6862\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 1s 3ms/step - loss: 0.3188 - accuracy: 0.9162 - val_loss: 0.6610 - val_accuracy: 0.6781\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3207 - accuracy: 0.9138 - val_loss: 0.6609 - val_accuracy: 0.6797\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function tanh : 0.752283105022831\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 2s 6ms/step - loss: 0.6913 - accuracy: 0.7158 - val_loss: 0.6948 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6492 - accuracy: 0.8202 - val_loss: 0.6478 - val_accuracy: 0.6789\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3958 - accuracy: 0.9111 - val_loss: 0.8416 - val_accuracy: 0.6520\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2744 - accuracy: 0.9131 - val_loss: 0.8666 - val_accuracy: 0.6528\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2760 - accuracy: 0.9136 - val_loss: 0.8880 - val_accuracy: 0.6479\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2677 - accuracy: 0.9140 - val_loss: 0.8929 - val_accuracy: 0.6487\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2724 - accuracy: 0.9140 - val_loss: 0.8610 - val_accuracy: 0.6724\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2673 - accuracy: 0.9156 - val_loss: 0.8652 - val_accuracy: 0.6748\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.9166 - val_loss: 0.8938 - val_accuracy: 0.6675\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2675 - accuracy: 0.9123 - val_loss: 1.0294 - val_accuracy: 0.6373\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2647 - accuracy: 0.9125 - val_loss: 1.0465 - val_accuracy: 0.6365\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2663 - accuracy: 0.9144 - val_loss: 0.9902 - val_accuracy: 0.6479\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2631 - accuracy: 0.9138 - val_loss: 1.0288 - val_accuracy: 0.6601\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2549 - accuracy: 0.9164 - val_loss: 0.9828 - val_accuracy: 0.6650\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2559 - accuracy: 0.9164 - val_loss: 1.0154 - val_accuracy: 0.6585\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2490 - accuracy: 0.9148 - val_loss: 0.9911 - val_accuracy: 0.6683\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2473 - accuracy: 0.9156 - val_loss: 1.0502 - val_accuracy: 0.6593\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2511 - accuracy: 0.9154 - val_loss: 0.9342 - val_accuracy: 0.6601\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2483 - accuracy: 0.9182 - val_loss: 1.0020 - val_accuracy: 0.6659\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.2420 - accuracy: 0.9180 - val_loss: 1.0171 - val_accuracy: 0.6724\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9178 - val_loss: 1.0466 - val_accuracy: 0.6748\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2454 - accuracy: 0.9189 - val_loss: 1.0344 - val_accuracy: 0.6773\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function selu : 0.7416286149162862\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 3s 8ms/step - loss: 0.6877 - accuracy: 0.7158 - val_loss: 0.6966 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6823 - accuracy: 0.7158 - val_loss: 0.6992 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6771 - accuracy: 0.7158 - val_loss: 0.7018 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6722 - accuracy: 0.7158 - val_loss: 0.7046 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.6675 - accuracy: 0.7158 - val_loss: 0.7076 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6630 - accuracy: 0.7158 - val_loss: 0.7106 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6587 - accuracy: 0.7158 - val_loss: 0.7137 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6547 - accuracy: 0.7158 - val_loss: 0.7169 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6509 - accuracy: 0.7158 - val_loss: 0.7202 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.6472 - accuracy: 0.7158 - val_loss: 0.7235 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6438 - accuracy: 0.7158 - val_loss: 0.7270 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6405 - accuracy: 0.7158 - val_loss: 0.7305 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6374 - accuracy: 0.7158 - val_loss: 0.7341 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6344 - accuracy: 0.7158 - val_loss: 0.7377 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6316 - accuracy: 0.7158 - val_loss: 0.7414 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6290 - accuracy: 0.7158 - val_loss: 0.7452 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6265 - accuracy: 0.7158 - val_loss: 0.7489 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6242 - accuracy: 0.7158 - val_loss: 0.7527 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6220 - accuracy: 0.7158 - val_loss: 0.7565 - val_accuracy: 0.4156\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6200 - accuracy: 0.7158 - val_loss: 0.7605 - val_accuracy: 0.4156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6180 - accuracy: 0.7158 - val_loss: 0.7643 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 0s 2ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 256, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 12 layers, 256 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db262fb",
   "metadata": {},
   "source": [
    "#### 16 layers and 1024 nodes initially"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "408c39ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "154/154 [==============================] - 4s 22ms/step - loss: 0.6916 - accuracy: 0.7158 - val_loss: 0.6944 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.6883 - accuracy: 0.7158 - val_loss: 0.6960 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.6841 - accuracy: 0.7158 - val_loss: 0.6985 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.5690 - accuracy: 0.7158 - val_loss: 0.6697 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.3551 - accuracy: 0.7158 - val_loss: 0.6688 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3384 - accuracy: 0.7158 - val_loss: 0.6668 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3343 - accuracy: 0.7158 - val_loss: 0.6722 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3344 - accuracy: 0.7158 - val_loss: 0.6731 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 3s 22ms/step - loss: 0.3295 - accuracy: 0.7158 - val_loss: 0.6706 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.3206 - accuracy: 0.7158 - val_loss: 0.6717 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3275 - accuracy: 0.9050 - val_loss: 0.6722 - val_accuracy: 0.6952\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 0.3259 - accuracy: 0.9123 - val_loss: 0.6808 - val_accuracy: 0.6805\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3189 - accuracy: 0.9150 - val_loss: 0.6860 - val_accuracy: 0.6748\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 2s 16ms/step - loss: 0.3157 - accuracy: 0.9172 - val_loss: 0.6789 - val_accuracy: 0.6960\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3146 - accuracy: 0.9113 - val_loss: 0.6968 - val_accuracy: 0.6936\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 4s 24ms/step - loss: 0.3129 - accuracy: 0.9129 - val_loss: 0.6908 - val_accuracy: 0.6927\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 3s 22ms/step - loss: 0.3114 - accuracy: 0.9148 - val_loss: 0.7034 - val_accuracy: 0.7009\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 4s 23ms/step - loss: 0.3042 - accuracy: 0.9185 - val_loss: 0.6899 - val_accuracy: 0.7090\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 3s 22ms/step - loss: 0.3016 - accuracy: 0.9191 - val_loss: 0.7029 - val_accuracy: 0.7213\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 4s 27ms/step - loss: 0.3006 - accuracy: 0.9148 - val_loss: 0.7334 - val_accuracy: 0.6716\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 0.3056 - accuracy: 0.9099 - val_loss: 0.7217 - val_accuracy: 0.7090\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.2922 - accuracy: 0.9172 - val_loss: 0.7404 - val_accuracy: 0.7294\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 3s 22ms/step - loss: 0.2921 - accuracy: 0.9144 - val_loss: 0.7519 - val_accuracy: 0.6707\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.2919 - accuracy: 0.9168 - val_loss: 0.7480 - val_accuracy: 0.7180\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 3s 22ms/step - loss: 0.2876 - accuracy: 0.9156 - val_loss: 0.7856 - val_accuracy: 0.7205\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.2824 - accuracy: 0.9248 - val_loss: 0.7780 - val_accuracy: 0.7384\n",
      "83/83 [==============================] - 1s 5ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function relu : 0.463089802130898\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 5s 20ms/step - loss: 0.6915 - accuracy: 0.7158 - val_loss: 0.6946 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.6855 - accuracy: 0.7174 - val_loss: 0.6898 - val_accuracy: 0.6895\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.6282 - accuracy: 0.8979 - val_loss: 0.6742 - val_accuracy: 0.6218\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.5817 - accuracy: 0.8917 - val_loss: 0.6725 - val_accuracy: 0.6055\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.5438 - accuracy: 0.9036 - val_loss: 0.6403 - val_accuracy: 0.6805\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.5152 - accuracy: 0.9044 - val_loss: 0.6631 - val_accuracy: 0.6194\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.4987 - accuracy: 0.8919 - val_loss: 0.6719 - val_accuracy: 0.6031\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.4892 - accuracy: 0.8777 - val_loss: 0.6632 - val_accuracy: 0.6218\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.4686 - accuracy: 0.8875 - val_loss: 0.6526 - val_accuracy: 0.6390\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.4429 - accuracy: 0.9050 - val_loss: 0.6539 - val_accuracy: 0.6373\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.4379 - accuracy: 0.8946 - val_loss: 0.6114 - val_accuracy: 0.6993\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.4251 - accuracy: 0.8960 - val_loss: 0.6133 - val_accuracy: 0.6952\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.4095 - accuracy: 0.9009 - val_loss: 0.6204 - val_accuracy: 0.6862\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.3972 - accuracy: 0.9042 - val_loss: 0.5731 - val_accuracy: 0.7433\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3892 - accuracy: 0.9038 - val_loss: 0.6046 - val_accuracy: 0.7066\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 3s 23ms/step - loss: 0.3781 - accuracy: 0.9076 - val_loss: 0.6070 - val_accuracy: 0.7050\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3767 - accuracy: 0.9046 - val_loss: 0.6123 - val_accuracy: 0.7001\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3701 - accuracy: 0.9056 - val_loss: 0.6191 - val_accuracy: 0.6960\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3626 - accuracy: 0.9048 - val_loss: 0.6495 - val_accuracy: 0.6650\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3583 - accuracy: 0.9042 - val_loss: 0.6768 - val_accuracy: 0.6430\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3544 - accuracy: 0.9025 - val_loss: 0.6878 - val_accuracy: 0.6373\n",
      "Epoch 22/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3470 - accuracy: 0.9036 - val_loss: 0.6909 - val_accuracy: 0.6381\n",
      "Epoch 23/200\n",
      "154/154 [==============================] - 4s 24ms/step - loss: 0.3417 - accuracy: 0.9046 - val_loss: 0.6283 - val_accuracy: 0.6993\n",
      "Epoch 24/200\n",
      "154/154 [==============================] - 4s 25ms/step - loss: 0.3382 - accuracy: 0.9048 - val_loss: 0.6693 - val_accuracy: 0.6634\n",
      "Epoch 25/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3344 - accuracy: 0.9052 - val_loss: 0.6635 - val_accuracy: 0.6740\n",
      "Epoch 26/200\n",
      "154/154 [==============================] - 4s 23ms/step - loss: 0.3318 - accuracy: 0.9048 - val_loss: 0.6671 - val_accuracy: 0.6740\n",
      "Epoch 27/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3290 - accuracy: 0.9048 - val_loss: 0.6706 - val_accuracy: 0.6740\n",
      "Epoch 28/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3265 - accuracy: 0.9048 - val_loss: 0.6743 - val_accuracy: 0.6740\n",
      "Epoch 29/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3242 - accuracy: 0.9048 - val_loss: 0.6780 - val_accuracy: 0.6740\n",
      "Epoch 30/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.3221 - accuracy: 0.9048 - val_loss: 0.6816 - val_accuracy: 0.6740\n",
      "Epoch 31/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.3203 - accuracy: 0.9048 - val_loss: 0.6851 - val_accuracy: 0.6740\n",
      "Epoch 32/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.3186 - accuracy: 0.9048 - val_loss: 0.6887 - val_accuracy: 0.6740\n",
      "Epoch 33/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.3171 - accuracy: 0.9048 - val_loss: 0.6923 - val_accuracy: 0.6740\n",
      "Epoch 34/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.3158 - accuracy: 0.9048 - val_loss: 0.6955 - val_accuracy: 0.6740\n",
      "83/83 [==============================] - 1s 6ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function tanh : 0.754185692541857\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 4s 20ms/step - loss: 0.6912 - accuracy: 0.7158 - val_loss: 0.6950 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.5261 - accuracy: 0.8638 - val_loss: 0.7609 - val_accuracy: 0.6316\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2431 - accuracy: 0.9113 - val_loss: 0.7704 - val_accuracy: 0.6667\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.2269 - accuracy: 0.9156 - val_loss: 0.9859 - val_accuracy: 0.6789\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 3s 21ms/step - loss: 0.2301 - accuracy: 0.9144 - val_loss: 1.4029 - val_accuracy: 0.6471\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.2226 - accuracy: 0.9168 - val_loss: 1.2124 - val_accuracy: 0.6773\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2205 - accuracy: 0.9180 - val_loss: 1.2292 - val_accuracy: 0.6993\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2187 - accuracy: 0.9152 - val_loss: 0.9148 - val_accuracy: 0.7294\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2127 - accuracy: 0.9170 - val_loss: 1.0543 - val_accuracy: 0.7294\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2089 - accuracy: 0.9121 - val_loss: 1.3321 - val_accuracy: 0.7384\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2130 - accuracy: 0.9131 - val_loss: 1.3226 - val_accuracy: 0.6732\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2077 - accuracy: 0.9170 - val_loss: 1.4304 - val_accuracy: 0.6936\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2103 - accuracy: 0.9166 - val_loss: 1.3101 - val_accuracy: 0.6781\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2101 - accuracy: 0.9162 - val_loss: 1.1710 - val_accuracy: 0.6968\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2077 - accuracy: 0.9178 - val_loss: 1.1595 - val_accuracy: 0.6797\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2040 - accuracy: 0.9191 - val_loss: 1.6421 - val_accuracy: 0.6740\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2029 - accuracy: 0.9158 - val_loss: 1.4304 - val_accuracy: 0.6830\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2084 - accuracy: 0.9191 - val_loss: 1.1400 - val_accuracy: 0.6773\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2083 - accuracy: 0.9166 - val_loss: 1.1212 - val_accuracy: 0.6870\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.2102 - accuracy: 0.9191 - val_loss: 1.3284 - val_accuracy: 0.6756\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.2078 - accuracy: 0.9182 - val_loss: 1.0030 - val_accuracy: 0.6919\n",
      "83/83 [==============================] - 1s 5ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function selu : 0.463089802130898\n",
      "Epoch 1/200\n",
      "154/154 [==============================] - 5s 19ms/step - loss: 0.6922 - accuracy: 0.5759 - val_loss: 0.6947 - val_accuracy: 0.4156\n",
      "Epoch 2/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.6867 - accuracy: 0.7158 - val_loss: 0.6971 - val_accuracy: 0.4156\n",
      "Epoch 3/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6815 - accuracy: 0.7158 - val_loss: 0.6995 - val_accuracy: 0.4156\n",
      "Epoch 4/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6765 - accuracy: 0.7158 - val_loss: 0.7022 - val_accuracy: 0.4156\n",
      "Epoch 5/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6717 - accuracy: 0.7158 - val_loss: 0.7049 - val_accuracy: 0.4156\n",
      "Epoch 6/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.6672 - accuracy: 0.7158 - val_loss: 0.7077 - val_accuracy: 0.4156\n",
      "Epoch 7/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6628 - accuracy: 0.7158 - val_loss: 0.7107 - val_accuracy: 0.4156\n",
      "Epoch 8/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6587 - accuracy: 0.7158 - val_loss: 0.7137 - val_accuracy: 0.4156\n",
      "Epoch 9/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6547 - accuracy: 0.7158 - val_loss: 0.7168 - val_accuracy: 0.4156\n",
      "Epoch 10/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6510 - accuracy: 0.7158 - val_loss: 0.7200 - val_accuracy: 0.4156\n",
      "Epoch 11/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6474 - accuracy: 0.7158 - val_loss: 0.7233 - val_accuracy: 0.4156\n",
      "Epoch 12/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6440 - accuracy: 0.7158 - val_loss: 0.7267 - val_accuracy: 0.4156\n",
      "Epoch 13/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6408 - accuracy: 0.7158 - val_loss: 0.7301 - val_accuracy: 0.4156\n",
      "Epoch 14/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6377 - accuracy: 0.7158 - val_loss: 0.7336 - val_accuracy: 0.4156\n",
      "Epoch 15/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6348 - accuracy: 0.7158 - val_loss: 0.7372 - val_accuracy: 0.4156\n",
      "Epoch 16/200\n",
      "154/154 [==============================] - 3s 17ms/step - loss: 0.6321 - accuracy: 0.7158 - val_loss: 0.7408 - val_accuracy: 0.4156\n",
      "Epoch 17/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.6295 - accuracy: 0.7158 - val_loss: 0.7444 - val_accuracy: 0.4156\n",
      "Epoch 18/200\n",
      "154/154 [==============================] - 3s 20ms/step - loss: 0.6271 - accuracy: 0.7158 - val_loss: 0.7481 - val_accuracy: 0.4156\n",
      "Epoch 19/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.6248 - accuracy: 0.7158 - val_loss: 0.7518 - val_accuracy: 0.4156\n",
      "Epoch 20/200\n",
      "154/154 [==============================] - 3s 18ms/step - loss: 0.6226 - accuracy: 0.7158 - val_loss: 0.7556 - val_accuracy: 0.4156\n",
      "Epoch 21/200\n",
      "154/154 [==============================] - 3s 19ms/step - loss: 0.6205 - accuracy: 0.7158 - val_loss: 0.7593 - val_accuracy: 0.4156\n",
      "83/83 [==============================] - 1s 6ms/step\n",
      "Model accuracy score with 8 layers, 64 nodes initially with activation function softmax : 0.463089802130898\n"
     ]
    }
   ],
   "source": [
    "for activation in ['relu','tanh','selu','softmax']:\n",
    "    # Initialising the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Dense(units = 1024, kernel_initializer = 'uniform', activation = activation, input_dim = 12))\n",
    "    model.add(Dense(units = 512, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 512, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 256, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 256, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 128, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 64, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 32, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(units = 16, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 8, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 4, kernel_initializer = 'uniform', activation = activation))\n",
    "    model.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.00009)\n",
    "    model.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    model.fit(x_train, y_train, batch_size = 32, epochs = 200, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred = (y_pred > 0.5)\n",
    "\n",
    "    print('Model accuracy score with 16 layers, 1024 nodes initially with activation function {0} : {1}'.format(activation,accuracy_score(y_test, y_pred)))\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbfff191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.87      0.73      1217\n",
      "           1       0.83      0.54      0.66      1411\n",
      "\n",
      "    accuracy                           0.70      2628\n",
      "   macro avg       0.73      0.71      0.69      2628\n",
      "weighted avg       0.74      0.70      0.69      2628\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ecc6a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60695a86",
   "metadata": {},
   "source": [
    "#### tanh activation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "624112db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "154/154 [==============================] - 2s 5ms/step - loss: 0.6916 - accuracy: 0.7158 - val_loss: 0.6945 - val_accuracy: 0.4156\n",
      "Epoch 2/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6873 - accuracy: 0.7158 - val_loss: 0.6974 - val_accuracy: 0.4156\n",
      "Epoch 3/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.6441 - accuracy: 0.8534 - val_loss: 0.6687 - val_accuracy: 0.6691\n",
      "Epoch 4/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5914 - accuracy: 0.9064 - val_loss: 0.6592 - val_accuracy: 0.6561\n",
      "Epoch 5/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5585 - accuracy: 0.9087 - val_loss: 0.6424 - val_accuracy: 0.6805\n",
      "Epoch 6/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5279 - accuracy: 0.9150 - val_loss: 0.6204 - val_accuracy: 0.7164\n",
      "Epoch 7/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.5050 - accuracy: 0.9144 - val_loss: 0.6147 - val_accuracy: 0.7148\n",
      "Epoch 8/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4858 - accuracy: 0.9140 - val_loss: 0.6299 - val_accuracy: 0.6748\n",
      "Epoch 9/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4665 - accuracy: 0.9140 - val_loss: 0.6198 - val_accuracy: 0.6862\n",
      "Epoch 10/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4508 - accuracy: 0.9136 - val_loss: 0.6089 - val_accuracy: 0.7042\n",
      "Epoch 11/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4372 - accuracy: 0.9154 - val_loss: 0.6172 - val_accuracy: 0.6887\n",
      "Epoch 12/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4226 - accuracy: 0.9164 - val_loss: 0.6047 - val_accuracy: 0.7017\n",
      "Epoch 13/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4108 - accuracy: 0.9164 - val_loss: 0.6323 - val_accuracy: 0.6659\n",
      "Epoch 14/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.4036 - accuracy: 0.9138 - val_loss: 0.5965 - val_accuracy: 0.7115\n",
      "Epoch 15/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3924 - accuracy: 0.9148 - val_loss: 0.5996 - val_accuracy: 0.7099\n",
      "Epoch 16/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3791 - accuracy: 0.9168 - val_loss: 0.6289 - val_accuracy: 0.6764\n",
      "Epoch 17/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3728 - accuracy: 0.9148 - val_loss: 0.6205 - val_accuracy: 0.6846\n",
      "Epoch 18/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.3650 - accuracy: 0.9156 - val_loss: 0.6458 - val_accuracy: 0.6634\n",
      "Epoch 19/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3590 - accuracy: 0.9144 - val_loss: 0.6662 - val_accuracy: 0.6438\n",
      "Epoch 20/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.9146 - val_loss: 0.6677 - val_accuracy: 0.6455\n",
      "Epoch 21/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3478 - accuracy: 0.9119 - val_loss: 0.6803 - val_accuracy: 0.6390\n",
      "Epoch 22/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3409 - accuracy: 0.9127 - val_loss: 0.6609 - val_accuracy: 0.6601\n",
      "Epoch 23/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3332 - accuracy: 0.9160 - val_loss: 0.6645 - val_accuracy: 0.6593\n",
      "Epoch 24/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3308 - accuracy: 0.9144 - val_loss: 0.6700 - val_accuracy: 0.6577\n",
      "Epoch 25/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3254 - accuracy: 0.9142 - val_loss: 0.6814 - val_accuracy: 0.6504\n",
      "Epoch 26/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.3216 - accuracy: 0.9129 - val_loss: 0.6743 - val_accuracy: 0.6585\n",
      "Epoch 27/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.3174 - accuracy: 0.9168 - val_loss: 0.6786 - val_accuracy: 0.6610\n",
      "Epoch 28/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.3140 - accuracy: 0.9140 - val_loss: 0.6852 - val_accuracy: 0.6585\n",
      "Epoch 29/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3102 - accuracy: 0.9150 - val_loss: 0.6923 - val_accuracy: 0.6561\n",
      "Epoch 30/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3058 - accuracy: 0.9158 - val_loss: 0.6914 - val_accuracy: 0.6585\n",
      "Epoch 31/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3001 - accuracy: 0.9168 - val_loss: 0.6947 - val_accuracy: 0.6593\n",
      "Epoch 32/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.3004 - accuracy: 0.9146 - val_loss: 0.6962 - val_accuracy: 0.6618\n",
      "Epoch 33/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.2986 - accuracy: 0.9134 - val_loss: 0.7016 - val_accuracy: 0.6593\n",
      "Epoch 34/150\n",
      "154/154 [==============================] - 1s 6ms/step - loss: 0.2951 - accuracy: 0.9156 - val_loss: 0.6899 - val_accuracy: 0.6707\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'tanh', input_dim = 12))\n",
    "model2.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'tanh'))\n",
    "model2.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "opt = Adam(learning_rate=0.00009)\n",
    "model2.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "history = model2.fit(x_train, y_train, batch_size = 32, epochs = 150, callbacks=[early_stopping], validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "39ab3ee6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.plot(history_df.loc[:, ['loss']], \"#BDE2E2\", label='Training loss')\n",
    "plt.plot(history_df.loc[:, ['val_loss']],\"#C2C4E2\", label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f8be4b7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.plot(history_df.loc[:, ['accuracy']], \"#BDE2E2\", label='Training accuracy')\n",
    "plt.plot(history_df.loc[:, ['val_accuracy']], \"#C2C4E2\", label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cf889c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAosAAAHSCAYAAACEg4G1AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAkrUlEQVR4nO3debhdZX0v8O+bSOagTAmSgclAQBlUBK3zAILcNuJ0EaTFgpT2YvVae8Vqna1itXp7C2JUxKIVRxQURJQq1jFQkRmMTAkhBBAlJCEDee8fOaTnHM46OVlwcnK6Pp/n2Q9nr7XevdfmeTh8z/e39t6l1hoAABjImJE+AQAAtl7CIgAAjYRFAAAaCYsAADQSFgEAaCQsAgDQ6HHD/QS3fu37PpsHGJJfT9ljpE8BGCXmHb5HGelzGK6Ms9urXjLir603zSIAAI2GvVkEAPjvaasqAIeNsAgA0EY3sqIxNAAAzTSLAACtdKNa1CwCANBIswgA0ELpRrGoWQQAGG1KKYeXUm4spSwspZw6yHHPKKU8VEp51eaufZiwCAAwipRSxiY5PckRSfZN8tpSyr4Nx52W5OLNXdubsAgA0EYpw3PbtIOTLKy13lxrXZPk3CTzBjjujUm+nmRZi7UbCYsAAKPLjCSLet1f3LNto1LKjCRHJTlzc9f2JywCAGxFSiknlVIu73U7qf8hAyzr/z3Vn0jytlrrQy3W9uHd0AAAW5Fa6/wk8wc5ZHGSWb3uz0yypN8xByU5t2wYa++Y5GWllHVDXNuHsAgA0MbIfXbOgiRzSim7J7kjydFJjul9QK1194d/LqWcneTbtdZvllIet6m1/QmLAABtjFBWrLWuK6Wckg3vch6b5Kxa67WllJN79ve/TnGTawd7PmERAGCUqbVemOTCftsGDIm11uM3tXYwwiIAQAsd+QIX74YGAKCZZhEAoI2OfDm0ZhEAgEbCIgAAjYyhAQDaMIYGAKDrhEUAABoZQwMAtGEMDQBA1wmLAAA0EhYBAGjkmkUAgBY6csmisAgA0E430qIxNAAAjTSLAABtdKNY1CwCANBMswgA0EZH3uGiWQQAoJGwCABAI2NoAIA2jKEBAOg6YREAgEbCIgAAjVyzCADQQkcuWRQWAQDa6UZaNIYGAKCRZhEAoI1uFIuaRQAAmmkWAQBa6Ua1KCwCALTRjaxoDA0AQDPNIgBAG5pFAAC6TrMIANBKN6pFzSIAAI00iwAALfhuaAAABtGNtGgMDQBAI80iAEAb3SgWNYsAADTTLAIAtNKNalFYBABooxtZ0RgaAIBmwiIAAI2ERQAAGrlmEQCgjY58hYuwCADQQjeiojE0AACD0CwCALTRkTG0ZhEAgEaaRQCANrpRLGoWAQBGm1LK4aWUG0spC0sppw6wf14p5apSypWllMtLKc/pte/WUsrVD+/b1HNpFgEARpFSytgkpyc5NMniJAtKKefXWq/rddgPkpxfa62llP2TfCXJ3F77X1hrvWcozycsAgC0MXJvcDk4ycJa680bTqOcm2Reko1hsdb6QK/jJyepbZ/MGBoAYHSZkWRRr/uLe7b1UUo5qpRyQ5LvJPnzXrtqku+VUq4opZy0qScTFgEAtiKllJN6rjN8+NY/0A1UaT6iOay1nldrnZvk5Une32vXs2utT0tyRJL/VUp53mDnYwwNALAVqbXOTzJ/kEMWJ5nV6/7MJEsGebzLSil7llJ2rLXeU2td0rN9WSnlvGwYa1/WtF6zCADQQillWG5DsCDJnFLK7qWUcUmOTnJ+v3N7Uul5sFLK05KMS3JvKWVyKWVqz/bJSQ5Lcs1gT6ZZBAAYRWqt60oppyS5OMnYJGfVWq8tpZzcs//MJK9M8qellLVJViX5nz3vjJ6e5LyeHPm4JP9Wa/3uYM8nLAIAjDK11guTXNhv25m9fj4tyWkDrLs5yQGb81zCIgBAG74bGgCArhMWAQBoZAwNANBGN6bQmkUAAJppFgEAWulGtahZBACgkWYRAKCNbhSLmkUAAJppFgEAWhji9ziPeppFAAAaCYsAADQyhgYAaMMYGgCArhMWAQBoZAwNANBGN6bQmkUAAJppFgEAWulGtahZBACgkWYRAKCNbhSLwiIAQBulI2nRGBoAgEaaRQCANrpRLAqLtHfbsjtzxgVfyfWLbsnkCZNy+EF/lNe96GUZO2ZohfX69evzxk9+JAuXLMp7jzs5z5y738Z9Vyy8Pt+74me5/vZbctfvf5fXvehlOe7FRw7XSwEeY3ctvS3f+tonc9utN2TCxMk5+FkvzaGHH5sxY8YOum7VqhW54BufyrVX/yy1rs/cJx+cea/8y0yevO3GY778xY/lil9+/xFr3/p38zNt+qwkydI7b8u3v/np3LnklqxccX+mTt0uc+Y+LS992Z9m28dv/9i+WPhvTlikleWrVubUs/5fZk/bOe9+3V/kznvvyfyLvpFaa44/9I+H9Bjfvfynuff+3w+47/KbrsvNS+/IgXvunR9edcVjeObAcFu5cnnmn/53mb7z7PzZie/KvffcmW9/69OptebwI/9s0LVfPPtDuXvZ4rzq6DellJILL/hcPv+Z9+Wv3vTRPsdNmz4rrz7mf/fZtt320zf+/OCDK7L9DtPz9Ge8ONs+fof87t6l+f7FX8wdi36TN/7NP2fs2MFDKwyJZhGafeeXP86atWvyrmPekMkTJiZPSlaufjBfuPQ7efVzX7Jh2yCWr1qZsy+5IH/+0nn5+HlffMT+Nxx+VP7iZa9Mkvzs+quG5TUAw+PnP7kw69auyZ+e8M5MmDA5SbJ69cpcctEX84IXv2rjtv5uu+X63HTDFTn5jR/JHk/aMGnY9gk75l/+6c35zY2/ypy9n7rx2G3GTciuu+3TeA677b5vdtt9343395yzfx7/hB3zmU++I3cuuSUzZz3psXip0Ane4EIrC266Nk+fs2+fUPiC/Z+e1WvX5upbFm5y/ecvuSD77rpHDtxz7wH3jxniKBvY+tx4/eXZa+7T+oTCA576/Kxduzo3L7y6cd0N1y/IlKnbbQyKSTJ7172z/Q4754brLn/U5zWpZ5T90ENrH/VjwQZlmG5bF/9HppVFd9+VWTtN77Nt2hO2z/htxmXRPUsHXXvz0jvyvf/8ed5wxFHDeYrACFl216Ls1HPt4MO2235athk3PsvuWty47u67Fmfa9JmP2D5t+qzcvWxR3+dYenv+/v+8Im9/yx/njE/8TX67cOAJxPr167Nu3dosu2txLrrgrMyavVdmzR74j1TYbN3IisbQtPPAqpUDjpqnTpyU5atWDrr2jAu+kj955vMyY4dpWXrfvcN1isAIWbXygUyc+MhR86SJU7Jq5QObWDflEdsnTpyS3937X3+EzpixZ2bvunem7Tw7Kx74Qy7792/kM2e8I3/5po9m9q59g+BZn3pXbrphw3XPM2bNyQl/8T6TC9hMmwyLpZS5SeYlmZGkJlmS5Pxa6/XDfG5s5Up55J8/tdZBP6T0h1ddnsX33JX3HnfycJ4aMMIG+j1Qkwzwa2OTamqfhc95wcv77N9n34Pz0Q/9Rf79ki/nz058V5998175l1m1cnnuuXtJfvC9L+WzZ/59/urNH8s224zb/BOBR9gKa8BhMOifV6WUtyU5Nxv+bfwyyYKen79USjl1+E+PrdWUiZOyYoAGccXqVZkyceA3t6x76KF8+rvn5TXPOyy11jywamVWrn4wSfLgmjUbfwZGt4mTpmTVqhWP2P7gqhWZMEBzOJR1AzWVD9tm3PjM3fcZuWPRI6+X3mnajMzebW6e9owX5cS//ECW3PHbXHnFvw/xlQDJppvFE5I8udba52rgUso/Jbk2yYcHWlRKOSnJSUnywZPenGMO9fl4/93M2ml6Ft1zV59ty35/Xx5csyazdtx5wDUPrlmde/7w+3zqwq/nUxd+vc++D335rDxx+x1z9t+8d9jOGdgypk2flWX9rjH8/X13Z82aBwe8JvFhO02fmVtuvuYR25fdtShP3u+PNv3Em6gtt9t+eiZOmpp77x38umoYqjZN+Wi0qbC4PskuSW7rt/2JPfsGVGudn2R+ktz6te/XR3OCbJ2esdeT89Uffz8rVz+YSeMnJEl+dPUVGb/NNtlv94E/kmLiuPH5yAlv6rPtvgfuz4e+/Lm8/rA/yYF77DXs5w0Mv733OSg/uvRrefDBlZkwYVKS5Ne/+lG22WZ8n3c69zd3n2fkBxd/Kbf89prsvudTkiSLbr8pv7t3aebue1DjurVrVufG6y/f5MfhLLtrcVauuD/bbz/wH7Sw2TqSFjcVFt+c5AellN8kefjPxNlJnpTklGE8L7ZyRx783Hzrpz/M+7746bzmeYdm6e/uyRcu/U5e8ewX93njy/Efe3f2331O3vKK12Xs2LE5oF8gfPgNLrtN3yVzZ+2+cftd992bm+7Y8DfKuoceym3L7syPr/nPTNhmfJ6x95O3wCsE2nrms1+Wn1z2rZzz2Q/kBS95de69985cctEX89wXHtXn43ROe/+fZ48999v44dq77r5P9pr79Hz5ix/LkfNO7PlQ7rOy2x5P3vgZi6tWrcjn5r87TzvoRdlhxydmxYr78x8/PC9/+P09Ofb4t2987G9/89MZM2ZsZu+6dyZMmpJlSxflR5d+NTvs+MQc+LTnb9l/ITDKDRoWa63fLaXsleTgbHiDS0myOMmCWutDW+D82EpNnTgpHz7hr3P6BV/Ju885M1MmTMwr/uhFeV2/r+Rbv3591q9vLKEb/fqWm/Kxr39h4/0fX/Or/PiaX2X6E7bPv/7t+x/1+QPDZ9KkqTnpf30o3/zaJ/O5T78nEydOznNfcFQOPeLYPsetX/9Q1te+vx+O/bNTc8F58/PVL308df367PPkQzLvlf/1hrjHPW6bTJny+Pzge1/KA8t/n222GZfZu+2Tk//6I5k1+7/+GJ05e05+ctkF+cXPLsq6tWvzhO12ylP2f05edOhrMq5nGgIMTal1eKfExtDAUP16yh4jfQrAKDHv8D1GfAa87MobhiXjTDtw7oi/tt58ziIAQBsduWbRJ5MCANBIWAQAoJExNABAG92YQmsWAQBoplkEAGilG9WiZhEAgEaaRQCAFjryyTnCIgBAO91Ii8bQAAA00iwCALTRjWJRswgAQDPNIgBAK92oFoVFAIA2upEVjaEBAGimWQQAaEOzCADA1qiUcngp5cZSysJSyqkD7J9XSrmqlHJlKeXyUspzhrq2P80iAEArI1MtllLGJjk9yaFJFidZUEo5v9Z6Xa/DfpDk/FprLaXsn+QrSeYOcW0fmkUAgBZKGZ7bEBycZGGt9eZa65ok5yaZ1/uAWusDtdbac3dykjrUtf0JiwAAo8uMJIt63V/cs62PUspRpZQbknwnyZ9vztrehEUAgFbKsNxKKSf1XGf48O2kAZ64v/qIDbWeV2udm+TlSd6/OWt7c80iAMBWpNY6P8n8QQ5ZnGRWr/szkywZ5PEuK6XsWUrZcXPXJppFAIB2hqdYHIoFSeaUUnYvpYxLcnSS8/ucWilPKmXDFZCllKclGZfk3qGs7U+zCAAwitRa15VSTklycZKxSc6qtV5bSjm5Z/+ZSV6Z5E9LKWuTrEryP3ve8DLg2sGeT1gEAGhl5D6Vu9Z6YZIL+207s9fPpyU5bahrByMsAgC04RtcAADoOmERAIBGwiIAAI1cswgA0MYQv5tvtBMWAQBa6EZUNIYGAGAQmkUAgDY6MobWLAIA0EizCADQRjeKRc0iAADNhEUAABoZQwMAtOENLgAAdJ2wCABAI2ERAIBGrlkEAGijI9csCosAAC10IyoaQwMAMAjNIgBAGx0ZQ2sWAQBoJCwCANDIGBoAoI1uTKE1iwAANNMsAgC04Q0uAAB0nbAIAEAjY2gAgBaKMTQAAF0nLAIA0EhYBACgkWsWAQDa6MYli8IiAEA73UiLxtAAADTSLAIAtNGNYlGzCABAM80iAEAr3agWNYsAADTSLAIAtNGNYlFYBABoo3QkLRpDAwDQSLMIANBGN4pFzSIAAM00iwAAbXSkWRQWAQBa6UZaNIYGAKCRZhEAoI1uFIuaRQAAmmkWAQBa6Ua1KCwCALTRjaxoDA0AQDPNIgBAC74bGgCArVIp5fBSyo2llIWllFMH2H9sKeWqnttPSykH9Np3aynl6lLKlaWUyzf1XJpFAIA2RqhYLKWMTXJ6kkOTLE6yoJRyfq31ul6H3ZLk+bXW+0opRySZn+SQXvtfWGu9ZyjPp1kEABhdDk6ysNZ6c611TZJzk8zrfUCt9ae11vt67v48ycy2TyYsAgCMLjOSLOp1f3HPtiYnJLmo1/2a5HullCtKKSdt6smMoQEA2ijDM4fuCXC9Q9z8Wuv83ocMsKw2PNYLsyEsPqfX5mfXWpeUUqYluaSUckOt9bKm8xEWAQC2Ij3BcP4ghyxOMqvX/ZlJlvQ/qJSyf5LPJDmi1npvr8df0vPPZaWU87JhrN0YFo2hAQBGlwVJ5pRSdi+ljEtydJLzex9QSpmd5BtJjqu13tRr++RSytSHf05yWJJrBnsyzSIAwChSa11XSjklycVJxiY5q9Z6bSnl5J79ZyZ5V5IdkpxRNozL19VaD0oyPcl5Pdsel+Tfaq3fHez5hEUAgDaG6ZrFoai1Xpjkwn7bzuz184lJThxg3c1JDui/fTDCIgBAG934AhfXLAIA0EyzCADQQkeKRc0iAADNNIsAAG2M4BtctiTNIgAAjYRFAAAaGUMDALRhDA0AQNcJiwAANBIWAQBo5JpFAIA2XLMIAEDXCYsAADQyhgYAaKEjU2jNIgAAzTSLAABtdKRaHPawOOG5Tx/upwD+mzjk1sUjfQoAQ1bTjbBoDA0AQCNjaACAFmod6TPYMjSLAAA00iwCALTSjWpRWAQAaMEYGgCAzhMWAQBoJCwCANDINYsAAC105JJFzSIAAM00iwAAbXSkWhQWAQBa6EhWNIYGAKCZZhEAoI2OfCq3ZhEAgEaaRQCAFrrRKwqLAADtdCQtGkMDANBIswgA0EJHikXNIgAAzTSLAABtdKRaFBYBAFroSFY0hgYAoJlmEQCgDd/gAgBA12kWAQBa6EavqFkEAGAQwiIAAI2MoQEAWujI+1s0iwAANBMWAQBoJCwCANDINYsAAC105ZpFYREAoJVupEVjaACAUaaUcngp5cZSysJSyqkD7D+2lHJVz+2npZQDhrq2P80iAEALIzWGLqWMTXJ6kkOTLE6yoJRyfq31ul6H3ZLk+bXW+0opRySZn+SQIa7tQ7MIADC6HJxkYa315lrrmiTnJpnX+4Ba609rrff13P15kplDXdufsAgAMLrMSLKo1/3FPduanJDkopZrjaEBANoYrjF0KeWkJCf12jS/1jq/9yEDnU7DY70wG8LiczZ37cOERQCArUhPMJw/yCGLk8zqdX9mkiX9Dyql7J/kM0mOqLXeuzlrezOGBgBooQ7TbQgWJJlTStm9lDIuydFJzu99QClldpJvJDmu1nrT5qztT7MIADCK1FrXlVJOSXJxkrFJzqq1XltKObln/5lJ3pVkhyRnlFKSZF2t9aCmtYM9X6nD/L7vpXfd141PrAQevVsXj/QZAKPEzofsN9C1d1vUHUuGJ+PM2GW7EX9tvRlDAwDQyBgaAKCF6uv+AADoOmERAIBGxtAAAC2M1HdDb2maRQAAGgmLAAA0MoYGAGjBGBoAgM4TFgEAaCQsAgDQyDWLAAAt1I5ctKhZBACgkbAIAEAjY2gAgBY6MoXWLAIA0ExYBACgkbAIAEAj1ywCALTgmkUAADpPWAQAoJExNABACx2ZQmsWAQBoplkEAGijI+9wERYBAFroRlQ0hgYAYBCaRQCANjpSLWoWAQBopFkEAGihI8WisAgA0EpH0qIxNAAAjTSLAAAtdKRY1CwCANBMswgA0EZHvsFFswgAQCPNIgBAC93oFYVFAIB2OpIWjaEBAGikWQQAaKEjxaJmEQCAZsIiAACNjKEBAFroyMcsahYBAGimWQQAaKUb1aJmEQCARppFAIAWXLMIAEDnCYsAADQyhgYAaMEYGgCAzhMWAQBoZAwNANCCMTQAAFulUsrhpZQbSykLSymnDrB/binlZ6WU1aWUt/bbd2sp5epSypWllMs39VyaRQCAVkamWiyljE1yepJDkyxOsqCUcn6t9bpeh/0uyV8neXnDw7yw1nrPUJ5PswgAMLocnGRhrfXmWuuaJOcmmdf7gFrrslrrgiRrH+2TCYsAAC3UOjy3IZiRZFGv+4t7tg351JN8r5RyRSnlpE0dbAwNALAV6QlwvUPc/Frr/N6HDLBsc2biz661LimlTEtySSnlhlrrZU0HC4sAAFuRnmA4f5BDFieZ1ev+zCRLNuPxl/T8c1kp5bxsGGsLi2wZt956S/7vJz6Wa6+9OlOmTM2R/+NPcvzxJ2Ts2LGNa66//rp885tfz9VX/Tr33HN3pk2bnpe85LC89pjjMn78+C149sBwufWORfm/53w21y68KVMmTc6Rz39xjj/q1Rk7pvl3wy2LF+WML30+v110W+5/YHm22/YJecZ+B+SEVx6dHZ6w3cbjzvrGl3PZ5b/IXffcnZqa2TvvkqNfNi8veuazt8RLo8NG8JNzFiSZU0rZPckdSY5OcsxQFpZSJicZU2td3vPzYUneN9gaYZHHzPLl9+ct//uN2W233fLBf/hIliy5I2ec/s+p69fnxDec3Lju3y/9fpbccUdee8zrMnPmrPz2twtz1mfn57e/XZj3f+DDW/AVAMNh+YoH8pbT3pfddpmZD775bVmybGnO+Ld/Ta01J77qtY3rVqxakZ13mpbDnv387Ljddrnz7mX5/De/mhtv+W0+9d7T8rieP0JXrlqZI577guy6y8yMHTMmP1zw87z3jI9nzJgxecHBz9pSLxO2mFrrulLKKUkuTjI2yVm11mtLKSf37D+zlLJzksuTbJtkfSnlzUn2TbJjkvNKKcmGHPhvtdbvDvZ8wiKPmW9967ysXr067//AaZk8eXKSZMWKFTn7c5/Ja485buO2/o459rg8oVdL8NSnPj3jxo3Pxz764Sxdemd23vmJW+T8geHxrUu/l9Vr1uT9b/rbTJ44KckBWbFqVc4+7yt57ZHzerY90lPmzM1T5szdeP+p+yQ7bb9D3vqR9+fmRbdlr932SJKccuzr+6x7xn4H5tY7FuXin/xIWGR4jWC1WGu9MMmF/bad2evnpdkwnu7v/iQHbM5zeTc0j5lf/PxnOfjgQ/qEwhe/+NCsXr06V175n43regfFh82Zs1eS5L777nvsTxTYon5x1a9y8H4H9AmFLz7k2Vm9Zk2uvOG6QVY+0uOnTE2SrF23btDjtp0yNes2cQwwNMIij5nbb78ts2fv2mfb9Ok7Z8KECbn99ts267GuvebqjBkz5hGPB4w+ty+5I7Of2PdTPabvuFMmjBuf25fcscn169evz9p1a3P7nXfkU1/5Qubu8aTss8eTHnHcuoceyvIVK3LJTy/L5df8On/yosMes9cAA6nDdNvaGEPzmFm+/P5M6fmrv7epU6dm+fLlQ36ce++9N+ecc3YOO+zwxtE1MHosX7kiUyY98r/lqZMnZ/nKBza5/m0f+4f88uorkyR777ZHTnvrOzJmTN+u49qFN+Wv3vd3SZKxY8fmzcedkOc+/eBHf/IwmI58ObSwyGOq54LZPmpNBtg8oLVr1+Y9735HJk6cmFPe+ObH9uSAETPg74YkZcCPi+vrTcedkPtXLM/ipUtzzvlfy//56AfzL+/8QMaPG7fxmD1mzc6n3vPhPLByZX7+6yvyiXM+m0kTJ+Ulz3rOY/kyoJNaj6FLKa8fZN9JpZTLSymXn3PO2W2fglFm6tRt88ADj2wQV6x4YMDGsb9aa/7hg+/NrbfenNM+8k+ZOnXb4ThNYAubOmlyHli54hHbV6xcOWDj2N/MnZ+YfffcK4c9+3n5x7/9+/zmtlvy/Z/9uM8xE8dPyNw9npSDnrJ/Tjn29Tnsj56XT335C4/Za4CBdGUM/WiuWXxv045a6/xa60G11oOOO+74R/EUjCazZ++a2/pdm7jsrruyatWqIV17+C//7xP5j//4cT74Dx/JrrvuNkxnCWxps3eZkdvu7Htt4rJ778mq1Q9m9i6b8w1lyc477pRtJ0/JnXcvG/S4vXbbI8t+d483ucBjYNAxdCnlqqZdSaY/9qfDaHbIM5+Vc7/0xaxcuSKTetqCSy/9fsaPH58DD3zaoGu/8IXP5xvf+Gre854PZP/9D9wCZwtsKYfs/9Sce+H5WblqVSZNnJgkufQXP8n4ceNy4Nx9N+uxbr/zjvzhgeV54k7TBj3u6t/ckJ223yGPe5yrrRhGW2MNOAw29V/R9CQvTdL/80tKkp8Oyxkxas2bd1S+/rWv5J3vPDXHHHNclixZkrPP/kxe85rX9nmjyjGvfVUOOOCpedup70iSXHLJxfn0/E/m8COOzI47Tcu1116z8dgZM2YM+NE6wOgx70WH5evfuzDv/Od/zDFHvjxL7r4rZ5/31bzm8D/u83E6x7z1lBwwd9+87cS/SpKc8aXPZ+yYsdlnzzmZMmlybluyOOde+K3MmLbzxm9nWXrP3fnwp0/PS571nOwybXpWPfhgLrvil7n05z/JW45/w4i8XrqjI1lxk2Hx20mm1Fqv7L+jlPLD4TghRq+pU7fNxz/xL/nExz+at5/6t5kyZUpe/eqjc/zrT+xz3EMPrcv69Q9tvH/5gl8kSb570Xfy3Yu+0+fYU9/+zhxxxP8Y/pMHhs3UyVPy8VPfnU/862fz9o9/OFMmTcqrX3pkjn/Fa/oc99D6h7J+/fqN9/fefc9845KLcsEPv581a9dk+g475nkHPTPH/vFRmTh+QpJkyqRJ2XG77XLO+V/P7/7w+0yZNDm77jIzp/3N3+WZBww+0QCGptRhftv30rvu60rwBh6tWxeP9BkAo8TOh+w3xM/ZGD5XXr10WDLOgfvtPOKvrTcfyg0AQCNX/gIAtNCV0almEQCARppFAIA2fN0fAABNuhEVjaEBABiEZhEAoI2OVIuaRQAAGmkWAQBa6EixKCwCALTSkbRoDA0AQCPNIgBACx0pFjWLAAA00ywCALRQO/INLppFAAAaCYsAADQyhgYAaKEbQ2jNIgAAg9AsAgC00ZFqUbMIAEAjzSIAQAsdKRaFRQCAVjqSFo2hAQBopFkEAGihdqRa1CwCANBIswgA0EY3ikVhEQCgjY5kRWNoAACaaRYBANroSLWoWQQAoJFmEQCghY4Ui8IiAEArHUmLxtAAADTSLAIAtOAbXAAA6DxhEQCARsIiAACNXLMIANBC7cYli5pFAACaCYsAADQyhgYAaMEYGgCAzhMWAQBGmVLK4aWUG0spC0sppw6wf24p5WellNWllLduztr+jKEBAFqoIzSHLqWMTXJ6kkOTLE6yoJRyfq31ul6H/S7JXyd5eYu1fWgWAQBGl4OTLKy13lxrXZPk3CTzeh9Qa11Wa12QZO3mru1PWAQAGF1mJFnU6/7inm3DslZYBADYipRSTiqlXN7rdlL/QwZYNtSZ+Gavdc0iAEALw3XJYq11fpL5gxyyOMmsXvdnJlkyxIff7LWaRQCA0WVBkjmllN1LKeOSHJ3k/OFaq1kEABhFaq3rSimnJLk4ydgkZ9Vary2lnNyz/8xSys5JLk+ybZL1pZQ3J9m31nr/QGsHez5hEQCghZH8Bpda64VJLuy37cxePy/NhhHzkNYOxhgaAIBGwiIAAI2ERQAAGrlmEQCghTrkjzYc3YRFAIA2upEVjaEBAGimWQQAaKEjxaJmEQCAZppFAIA2OlItCosAAC10JCsaQwMA0EyzCADQRkeqRc0iAACNNIsAAC34BhcAAJp1IysaQwMA0EyzCADQQkeKRc0iAADNNIsAAG10pFrULAIA0EizCADQQkeKRc0iAADNhEUAABoZQwMAtFBrNwbRmkUAABoJiwAANDKGBgBooSNTaM0iAADNhEUAABoJiwAANHLNIgBAC65ZBACg84RFAAAaGUMDALTgG1wAAOg8YREAgEbCIgAAjVyzCADQQkcuWdQsAgDQTFgEAKCRMTQAQAsdmUJrFgEAaKZZBABooyPVorAIANBCR7KiMTQAAM00iwAAbXTkgxY1iwAANNIsAgC00I1eUVgEAGinI2nRGBoAgEaaRQCAFjpSLGoWAQBoVmpH3vbN1qWUclKtdf5Inwew9fP7AkaWZpGRctJInwAwavh9ASNIWAQAoJGwCABAI2GRkeL6I2Co/L6AEeQNLgAANNIsAgDQSFhkiyulHF5KubGUsrCUcupInw+wdSqlnFVKWVZKuWakzwW6TFhkiyqljE1yepIjkuyb5LWllH1H9qyArdTZSQ4f6ZOArhMW2dIOTrKw1npzrXVNknOTzBvhcwK2QrXWy5L8bqTPA7pOWGRLm5FkUa/7i3u2AQBbIWGRLa0MsM1b8gFgKyUssqUtTjKr1/2ZSZaM0LkAAJsgLLKlLUgyp5SyeyllXJKjk5w/wucEADQQFtmiaq3rkpyS5OIk1yf5Sq312pE9K2BrVEr5UpKfJdm7lLK4lHLCSJ8TdJFvcAEAoJFmEQCARsIiAACNhEUAABoJiwAANBIWAQBoJCwCANBIWAQAoJGwCABAo/8PTFJ1eWT/uO0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "y_pred = model2.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "# confusion matrix\n",
    "cmap1 = sns.diverging_palette(260,-10,s=50, l=75, n=5, as_cmap=True)\n",
    "plt.subplots(figsize=(8,6))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9a77e7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.88      0.76      1217\n",
      "           1       0.86      0.62      0.72      1411\n",
      "\n",
      "    accuracy                           0.74      2628\n",
      "   macro avg       0.77      0.75      0.74      2628\n",
      "weighted avg       0.77      0.74      0.74      2628\n",
      "\n",
      "0.7431506849315068\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d62d29f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e61d8863",
   "metadata": {},
   "source": [
    "#### selu activation model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0856df8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "154/154 [==============================] - 2s 7ms/step - loss: 0.6913 - accuracy: 0.7156 - val_loss: 0.6948 - val_accuracy: 0.4156\n",
      "Epoch 2/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.6446 - accuracy: 0.8275 - val_loss: 0.6515 - val_accuracy: 0.6528\n",
      "Epoch 3/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.3982 - accuracy: 0.9117 - val_loss: 0.8047 - val_accuracy: 0.6610\n",
      "Epoch 4/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2876 - accuracy: 0.9140 - val_loss: 0.9531 - val_accuracy: 0.6504\n",
      "Epoch 5/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2896 - accuracy: 0.9168 - val_loss: 0.9857 - val_accuracy: 0.6528\n",
      "Epoch 6/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2883 - accuracy: 0.9150 - val_loss: 0.9838 - val_accuracy: 0.6593\n",
      "Epoch 7/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2771 - accuracy: 0.9148 - val_loss: 1.0581 - val_accuracy: 0.6626\n",
      "Epoch 8/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2802 - accuracy: 0.9152 - val_loss: 1.0343 - val_accuracy: 0.6773\n",
      "Epoch 9/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2756 - accuracy: 0.9091 - val_loss: 1.0245 - val_accuracy: 0.6601\n",
      "Epoch 10/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2750 - accuracy: 0.9129 - val_loss: 0.9244 - val_accuracy: 0.6740\n",
      "Epoch 11/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2788 - accuracy: 0.9125 - val_loss: 0.9083 - val_accuracy: 0.6724\n",
      "Epoch 12/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2675 - accuracy: 0.9150 - val_loss: 0.9845 - val_accuracy: 0.6707\n",
      "Epoch 13/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2646 - accuracy: 0.9162 - val_loss: 1.0091 - val_accuracy: 0.6634\n",
      "Epoch 14/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2622 - accuracy: 0.9156 - val_loss: 0.9570 - val_accuracy: 0.6667\n",
      "Epoch 15/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.9148 - val_loss: 1.0235 - val_accuracy: 0.6544\n",
      "Epoch 16/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2572 - accuracy: 0.9154 - val_loss: 1.0622 - val_accuracy: 0.6642\n",
      "Epoch 17/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2519 - accuracy: 0.9166 - val_loss: 0.9766 - val_accuracy: 0.6732\n",
      "Epoch 18/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2553 - accuracy: 0.9146 - val_loss: 0.9748 - val_accuracy: 0.6748\n",
      "Epoch 19/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2468 - accuracy: 0.9170 - val_loss: 1.1056 - val_accuracy: 0.6716\n",
      "Epoch 20/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2488 - accuracy: 0.9166 - val_loss: 0.9953 - val_accuracy: 0.6764\n",
      "Epoch 21/150\n",
      "154/154 [==============================] - 1s 4ms/step - loss: 0.2497 - accuracy: 0.9164 - val_loss: 1.0229 - val_accuracy: 0.6781\n",
      "Epoch 22/150\n",
      "154/154 [==============================] - 1s 5ms/step - loss: 0.2438 - accuracy: 0.9166 - val_loss: 1.0621 - val_accuracy: 0.6789\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(Dense(units = 256, kernel_initializer = 'uniform', activation = 'selu', input_dim = 12))\n",
    "model2.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 128, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 64, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 32, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 16, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 8, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(Dense(units = 4, kernel_initializer = 'uniform', activation = 'selu'))\n",
    "model2.add(Dense(units = 1, kernel_initializer = 'uniform', activation = 'sigmoid'))\n",
    "\n",
    "# Compiling the ANN\n",
    "opt = Adam(learning_rate=0.00009)\n",
    "model2.compile(optimizer = opt, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "# Train the ANN\n",
    "history = model2.fit(x_train, y_train, batch_size = 32, epochs = 150, callbacks=[early_stopping], validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f66b16bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.plot(history_df.loc[:, ['loss']], \"#BDE2E2\", label='Training loss')\n",
    "plt.plot(history_df.loc[:, ['val_loss']],\"#C2C4E2\", label='Validation loss')\n",
    "plt.title('Training and Validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc=\"best\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02e0f986",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "plt.plot(history_df.loc[:, ['accuracy']], \"#BDE2E2\", label='Training accuracy')\n",
    "plt.plot(history_df.loc[:, ['val_accuracy']], \"#C2C4E2\", label='Validation accuracy')\n",
    "\n",
    "plt.title('Training and Validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "474a09f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83/83 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model2.predict(x_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "# confusion matrix\n",
    "cmap1 = sns.diverging_palette(260,-10,s=50, l=75, n=5, as_cmap=True)\n",
    "plt.subplots(figsize=(12,8))\n",
    "cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(cf_matrix/np.sum(cf_matrix), cmap = cmap1, annot = True, annot_kws = {'size':15})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "82d7cc6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.83      0.74      1217\n",
      "           1       0.81      0.63      0.71      1411\n",
      "\n",
      "    accuracy                           0.72      2628\n",
      "   macro avg       0.74      0.73      0.72      2628\n",
      "weighted avg       0.74      0.72      0.72      2628\n",
      "\n",
      "0.724124809741248\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0af7c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1002c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
